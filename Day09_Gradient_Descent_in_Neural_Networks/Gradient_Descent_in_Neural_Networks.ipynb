{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0693fee",
   "metadata": {},
   "source": [
    "# Batch vs Stochastics vs Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6569c2",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fa5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13277346",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ad3bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'./Social_Network_Ads.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980a59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2fc1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16c710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfd6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569154e+07</td>\n",
       "      <td>37.655000</td>\n",
       "      <td>69742.500000</td>\n",
       "      <td>0.357500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.165832e+04</td>\n",
       "      <td>10.482877</td>\n",
       "      <td>34096.960282</td>\n",
       "      <td>0.479864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.556669e+07</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.562676e+07</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>43000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569434e+07</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.575036e+07</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.581524e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User ID         Age  EstimatedSalary   Purchased\n",
       "count  4.000000e+02  400.000000       400.000000  400.000000\n",
       "mean   1.569154e+07   37.655000     69742.500000    0.357500\n",
       "std    7.165832e+04   10.482877     34096.960282    0.479864\n",
       "min    1.556669e+07   18.000000     15000.000000    0.000000\n",
       "25%    1.562676e+07   29.750000     43000.000000    0.000000\n",
       "50%    1.569434e+07   37.000000     70000.000000    0.000000\n",
       "75%    1.575036e+07   46.000000     88000.000000    1.000000\n",
       "max    1.581524e+07   60.000000    150000.000000    1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec92fe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User ID</th>\n",
       "      <td>400.0</td>\n",
       "      <td>1.569154e+07</td>\n",
       "      <td>71658.321581</td>\n",
       "      <td>15566689.0</td>\n",
       "      <td>15626763.75</td>\n",
       "      <td>15694341.5</td>\n",
       "      <td>15750363.0</td>\n",
       "      <td>15815236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>400.0</td>\n",
       "      <td>3.765500e+01</td>\n",
       "      <td>10.482877</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.75</td>\n",
       "      <td>37.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>400.0</td>\n",
       "      <td>6.974250e+04</td>\n",
       "      <td>34096.960282</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>43000.00</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchased</th>\n",
       "      <td>400.0</td>\n",
       "      <td>3.575000e-01</td>\n",
       "      <td>0.479864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean           std         min          25%  \\\n",
       "User ID          400.0  1.569154e+07  71658.321581  15566689.0  15626763.75   \n",
       "Age              400.0  3.765500e+01     10.482877        18.0        29.75   \n",
       "EstimatedSalary  400.0  6.974250e+04  34096.960282     15000.0     43000.00   \n",
       "Purchased        400.0  3.575000e-01      0.479864         0.0         0.00   \n",
       "\n",
       "                        50%         75%         max  \n",
       "User ID          15694341.5  15750363.0  15815236.0  \n",
       "Age                    37.0        46.0        60.0  \n",
       "EstimatedSalary     70000.0     88000.0    150000.0  \n",
       "Purchased               0.0         1.0         1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1634d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need \"User ID\", \"Gender\" so let's drop this colums\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "795767dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['User ID', 'Gender']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f44880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can do it \n",
    "# df = df[['Age','EstimatedSalary','Purchased']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf5fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:2]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889293a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary\n",
       "0     19            19000\n",
       "1     35            20000\n",
       "2     26            43000\n",
       "3     27            57000\n",
       "4     19            76000\n",
       "..   ...              ...\n",
       "395   46            41000\n",
       "396   51            23000\n",
       "397   50            20000\n",
       "398   36            33000\n",
       "399   49            36000\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830dcafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "395    1\n",
       "396    1\n",
       "397    1\n",
       "398    0\n",
       "399    1\n",
       "Name: Purchased, Length: 400, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5053784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5602e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d870ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.78179743, -1.49004624],\n",
       "       [-0.25358736, -1.46068138],\n",
       "       [-1.11320552, -0.78528968],\n",
       "       [-1.01769239, -0.37418169],\n",
       "       [-1.78179743,  0.18375059],\n",
       "       [-1.01769239, -0.34481683],\n",
       "       [-1.01769239,  0.41866944],\n",
       "       [-0.54012675,  2.35674998],\n",
       "       [-1.20871865, -1.07893824],\n",
       "       [-0.25358736, -0.13926283],\n",
       "       [-1.11320552,  0.30121002],\n",
       "       [-1.11320552, -0.52100597],\n",
       "       [-1.6862843 ,  0.47739916],\n",
       "       [-0.54012675, -1.51941109],\n",
       "       [-1.87731056,  0.35993973],\n",
       "       [-0.82666613,  0.30121002],\n",
       "       [ 0.89257019, -1.3138571 ],\n",
       "       [ 0.70154394, -1.28449224],\n",
       "       [ 0.79705706, -1.22576253],\n",
       "       [ 0.98808332, -1.19639767],\n",
       "       [ 0.70154394, -1.40195167],\n",
       "       [ 0.89257019, -0.60910054],\n",
       "       [ 0.98808332, -0.84401939],\n",
       "       [ 0.70154394, -1.40195167],\n",
       "       [ 0.79705706, -1.37258681],\n",
       "       [ 0.89257019, -1.46068138],\n",
       "       [ 1.08359645, -1.22576253],\n",
       "       [ 0.89257019, -1.16703281],\n",
       "       [-0.82666613, -0.78528968],\n",
       "       [-0.63563988, -1.51941109],\n",
       "       [-0.63563988,  0.12502088],\n",
       "       [-1.01769239,  1.97500684],\n",
       "       [-1.59077117, -1.5781408 ],\n",
       "       [-0.92217926, -0.75592482],\n",
       "       [-1.01769239,  0.59485858],\n",
       "       [-0.25358736, -1.25512738],\n",
       "       [-0.44461362, -1.22576253],\n",
       "       [-0.73115301, -0.60910054],\n",
       "       [-1.11320552,  0.06629116],\n",
       "       [-1.01769239, -1.13766796],\n",
       "       [-1.01769239, -1.54877595],\n",
       "       [-0.44461362, -0.55037082],\n",
       "       [-0.25358736,  1.123426  ],\n",
       "       [-0.73115301, -1.60750566],\n",
       "       [-0.92217926,  0.41866944],\n",
       "       [-1.39974491, -1.46068138],\n",
       "       [-1.20871865,  0.27184516],\n",
       "       [-1.01769239, -0.46227625],\n",
       "       [-0.73115301,  1.91627713],\n",
       "       [-0.63563988,  0.56549373],\n",
       "       [-1.30423178, -1.1083031 ],\n",
       "       [-1.87731056, -0.75592482],\n",
       "       [-0.82666613,  0.38930459],\n",
       "       [-0.25358736, -1.37258681],\n",
       "       [-1.01769239, -0.34481683],\n",
       "       [-1.30423178, -0.4329114 ],\n",
       "       [-1.39974491, -0.63846539],\n",
       "       [-0.92217926,  0.27184516],\n",
       "       [-1.49525804, -1.51941109],\n",
       "       [-0.54012675,  1.38770971],\n",
       "       [-1.01769239, -1.46068138],\n",
       "       [-1.20871865,  0.50676401],\n",
       "       [-1.39974491, -0.10989798],\n",
       "       [-0.54012675,  1.47580428],\n",
       "       [ 2.03872775,  0.38930459],\n",
       "       [-1.30423178, -0.34481683],\n",
       "       [-1.30423178, -1.49004624],\n",
       "       [-1.39974491,  0.35993973],\n",
       "       [-1.49525804, -0.19799255],\n",
       "       [-0.63563988, -0.05116826],\n",
       "       [-1.20871865,  0.30121002],\n",
       "       [-1.30423178, -1.25512738],\n",
       "       [-1.6862843 , -1.37258681],\n",
       "       [-0.44461362,  1.27025028],\n",
       "       [-0.54012675, -1.51941109],\n",
       "       [-0.34910049,  1.24088543],\n",
       "       [-1.87731056, -0.52100597],\n",
       "       [-1.49525804, -1.25512738],\n",
       "       [-0.92217926,  0.50676401],\n",
       "       [-1.11320552, -1.54877595],\n",
       "       [-0.73115301,  0.30121002],\n",
       "       [ 0.12846516, -0.81465453],\n",
       "       [-1.6862843 , -0.60910054],\n",
       "       [-0.25358736,  0.53612887],\n",
       "       [-0.73115301, -0.2273574 ],\n",
       "       [-0.63563988,  1.41707457],\n",
       "       [-1.30423178, -0.4329114 ],\n",
       "       [-0.92217926,  0.4480343 ],\n",
       "       [-1.11320552,  0.33057487],\n",
       "       [-0.25358736, -0.57973568],\n",
       "       [-1.49525804,  0.33057487],\n",
       "       [-0.73115301,  1.35834485],\n",
       "       [-1.11320552, -1.60750566],\n",
       "       [-0.82666613, -1.22576253],\n",
       "       [-0.82666613,  0.38930459],\n",
       "       [-0.25358736, -0.75592482],\n",
       "       [-0.25358736, -1.3138571 ],\n",
       "       [-0.92217926,  1.56389885],\n",
       "       [-0.25358736,  0.09565602],\n",
       "       [-0.92217926, -0.96147882],\n",
       "       [-1.01769239,  0.53612887],\n",
       "       [-0.92217926, -0.31545197],\n",
       "       [-0.54012675,  0.47739916],\n",
       "       [-0.44461362,  2.32738512],\n",
       "       [-1.78179743, -1.43131652],\n",
       "       [-1.59077117,  0.06629116],\n",
       "       [-1.11320552, -1.02020853],\n",
       "       [-1.01769239,  0.56549373],\n",
       "       [-1.11320552,  0.47739916],\n",
       "       [ 0.03295203,  0.30121002],\n",
       "       [ 0.12846516,  0.03692631],\n",
       "       [-0.0625611 ,  0.03692631],\n",
       "       [ 0.03295203, -0.25672226],\n",
       "       [-0.0625611 , -0.4329114 ],\n",
       "       [ 0.41500455,  0.30121002],\n",
       "       [ 0.22397829, -0.37418169],\n",
       "       [-0.25358736,  0.15438573],\n",
       "       [-0.15807423, -0.52100597],\n",
       "       [ 0.22397829, -0.31545197],\n",
       "       [ 0.31949142, -0.31545197],\n",
       "       [-0.15807423,  0.15438573],\n",
       "       [-0.0625611 ,  0.06629116],\n",
       "       [ 0.22397829,  0.15438573],\n",
       "       [-0.25358736, -0.49164111],\n",
       "       [ 0.31949142, -0.55037082],\n",
       "       [ 0.12846516, -0.25672226],\n",
       "       [ 0.41500455, -0.13926283],\n",
       "       [-1.11320552, -1.1083031 ],\n",
       "       [-0.73115301, -1.54877595],\n",
       "       [-1.11320552,  0.41866944],\n",
       "       [-0.63563988, -0.34481683],\n",
       "       [-0.44461362, -1.13766796],\n",
       "       [-0.73115301,  0.50676401],\n",
       "       [-1.59077117, -0.05116826],\n",
       "       [-0.92217926, -0.4329114 ],\n",
       "       [-1.39974491, -0.19799255],\n",
       "       [-1.6862843 ,  0.35993973],\n",
       "       [-0.73115301,  1.09406114],\n",
       "       [-0.92217926, -0.31545197],\n",
       "       [-1.78179743, -1.3138571 ],\n",
       "       [-1.78179743,  0.4480343 ],\n",
       "       [-1.87731056, -0.05116826],\n",
       "       [-0.25358736, -0.31545197],\n",
       "       [-0.73115301,  0.56549373],\n",
       "       [-0.34910049, -1.3138571 ],\n",
       "       [-1.30423178,  0.56549373],\n",
       "       [-1.01769239,  0.77104772],\n",
       "       [ 0.31949142, -1.16703281],\n",
       "       [-0.82666613, -0.25672226],\n",
       "       [-1.6862843 ,  0.12502088],\n",
       "       [-1.11320552, -1.60750566],\n",
       "       [ 0.31949142, -0.72655996],\n",
       "       [-0.63563988,  0.18375059],\n",
       "       [-0.15807423, -0.57973568],\n",
       "       [ 0.22397829, -0.66783025],\n",
       "       [-0.63563988, -1.60750566],\n",
       "       [ 0.79705706, -0.31545197],\n",
       "       [-0.82666613,  0.15438573],\n",
       "       [-1.11320552, -1.16703281],\n",
       "       [-0.54012675,  1.91627713],\n",
       "       [-0.54012675,  0.88850715],\n",
       "       [-1.20871865,  0.59485858],\n",
       "       [-0.0625611 , -1.07893824],\n",
       "       [-0.25358736, -0.93211396],\n",
       "       [-0.44461362, -0.02180341],\n",
       "       [-1.87731056,  0.47739916],\n",
       "       [-1.49525804, -0.4329114 ],\n",
       "       [-0.25358736,  0.03692631],\n",
       "       [-0.82666613,  2.29802026],\n",
       "       [-0.82666613, -0.66783025],\n",
       "       [-1.59077117,  0.53612887],\n",
       "       [-0.34910049,  1.32898   ],\n",
       "       [-1.11320552,  1.41707457],\n",
       "       [-0.34910049, -0.78528968],\n",
       "       [-0.34910049,  0.06629116],\n",
       "       [-1.39974491, -1.22576253],\n",
       "       [-0.25358736, -0.66783025],\n",
       "       [-1.20871865, -1.40195167],\n",
       "       [-1.30423178, -1.37258681],\n",
       "       [-0.63563988, -1.04957339],\n",
       "       [-1.11320552, -1.5781408 ],\n",
       "       [-0.63563988,  0.03692631],\n",
       "       [-0.54012675,  1.38770971],\n",
       "       [-0.44461362, -0.78528968],\n",
       "       [-0.44461362, -0.28608712],\n",
       "       [-0.63563988, -0.10989798],\n",
       "       [-1.6862843 ,  0.35993973],\n",
       "       [-0.44461362, -0.84401939],\n",
       "       [-0.25358736,  0.06629116],\n",
       "       [-0.92217926, -1.1083031 ],\n",
       "       [-1.30423178,  0.41866944],\n",
       "       [-1.78179743, -1.28449224],\n",
       "       [-0.82666613, -0.78528968],\n",
       "       [-1.78179743,  0.00756145],\n",
       "       [-0.92217926,  0.56549373],\n",
       "       [-0.34910049, -0.78528968],\n",
       "       [-0.73115301,  0.27184516],\n",
       "       [-1.6862843 , -0.99084367],\n",
       "       [-1.11320552,  0.30121002],\n",
       "       [-0.25358736, -1.40195167],\n",
       "       [-0.25358736, -0.9027491 ],\n",
       "       [ 1.08359645,  0.12502088],\n",
       "       [ 0.12846516,  1.88691227],\n",
       "       [ 0.31949142,  0.03692631],\n",
       "       [ 1.94321462,  0.917872  ],\n",
       "       [ 0.89257019, -0.66783025],\n",
       "       [ 1.65667523,  1.76945285],\n",
       "       [ 1.37013584,  1.29961514],\n",
       "       [ 0.22397829,  2.12183112],\n",
       "       [ 0.79705706, -1.40195167],\n",
       "       [ 0.98808332,  0.77104772],\n",
       "       [ 1.37013584,  2.35674998],\n",
       "       [ 2.03872775, -0.81465453],\n",
       "       [-0.25358736, -0.34481683],\n",
       "       [ 0.89257019, -0.78528968],\n",
       "       [ 2.13424088,  1.123426  ],\n",
       "       [ 1.08359645, -0.13926283],\n",
       "       [ 0.22397829,  0.2424803 ],\n",
       "       [ 0.79705706,  0.77104772],\n",
       "       [ 2.03872775,  2.15119598],\n",
       "       [ 0.31949142,  0.30121002],\n",
       "       [-0.25358736,  0.62422344],\n",
       "       [-0.0625611 ,  2.18056084],\n",
       "       [ 2.13424088,  0.94723686],\n",
       "       [-0.25358736, -0.28608712],\n",
       "       [-0.0625611 , -0.49164111],\n",
       "       [-0.15807423,  1.65199342],\n",
       "       [ 1.75218836,  1.85754742],\n",
       "       [ 0.22397829,  0.06629116],\n",
       "       [ 0.41500455,  0.30121002],\n",
       "       [-0.25358736,  2.26865541],\n",
       "       [ 0.12846516, -0.81465453],\n",
       "       [ 0.22397829,  1.09406114],\n",
       "       [ 1.08359645,  0.47739916],\n",
       "       [ 0.03295203,  1.24088543],\n",
       "       [ 0.79705706,  0.27184516],\n",
       "       [ 0.22397829, -0.37418169],\n",
       "       [-0.0625611 ,  0.30121002],\n",
       "       [ 0.79705706,  0.35993973],\n",
       "       [ 1.46564897,  2.15119598],\n",
       "       [ 0.41500455,  2.32738512],\n",
       "       [ 0.03295203, -0.31545197],\n",
       "       [ 1.17910958,  0.53612887],\n",
       "       [ 1.75218836,  1.00596657],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 1.27462271,  2.23929055],\n",
       "       [-0.25358736, -0.57973568],\n",
       "       [ 1.84770149,  1.53453399],\n",
       "       [ 0.31949142, -0.52100597],\n",
       "       [-0.25358736,  0.80041258],\n",
       "       [ 0.60603081, -0.9027491 ],\n",
       "       [-0.0625611 , -0.52100597],\n",
       "       [ 0.98808332,  1.88691227],\n",
       "       [-0.0625611 ,  2.23929055],\n",
       "       [ 1.17910958, -0.75592482],\n",
       "       [ 1.37013584,  0.59485858],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 0.22397829, -0.37418169],\n",
       "       [ 1.94321462,  0.74168287],\n",
       "       [ 0.70154394,  1.7988177 ],\n",
       "       [-0.25358736,  0.21311545],\n",
       "       [-0.15807423,  2.18056084],\n",
       "       [ 1.65667523,  1.62262856],\n",
       "       [-0.25358736,  0.06629116],\n",
       "       [ 0.98808332,  0.59485858],\n",
       "       [ 0.41500455,  1.123426  ],\n",
       "       [ 0.22397829,  0.15438573],\n",
       "       [-0.0625611 ,  0.12502088],\n",
       "       [ 0.89257019,  2.18056084],\n",
       "       [ 0.22397829, -0.25672226],\n",
       "       [ 0.51051768,  1.85754742],\n",
       "       [ 2.03872775,  0.18375059],\n",
       "       [ 2.13424088, -0.81465453],\n",
       "       [ 0.12846516,  1.06469629],\n",
       "       [ 1.84770149, -1.28449224],\n",
       "       [ 1.84770149,  0.12502088],\n",
       "       [ 0.03295203,  0.03692631],\n",
       "       [ 1.08359645,  0.53612887],\n",
       "       [ 1.37013584, -0.93211396],\n",
       "       [ 1.17910958, -0.99084367],\n",
       "       [ 2.03872775,  0.53612887],\n",
       "       [-0.25358736, -0.25672226],\n",
       "       [-0.0625611 ,  0.00756145],\n",
       "       [ 1.37013584, -1.43131652],\n",
       "       [ 0.98808332,  2.09246627],\n",
       "       [-0.0625611 ,  0.68295315],\n",
       "       [-0.0625611 , -0.2273574 ],\n",
       "       [ 0.98808332,  2.0043717 ],\n",
       "       [ 0.31949142,  0.27184516],\n",
       "       [-0.0625611 ,  0.2424803 ],\n",
       "       [ 0.12846516,  1.88691227],\n",
       "       [ 1.08359645,  0.56549373],\n",
       "       [ 1.65667523, -0.9027491 ],\n",
       "       [-0.0625611 ,  0.21311545],\n",
       "       [-0.25358736, -0.37418169],\n",
       "       [-0.15807423, -0.19799255],\n",
       "       [ 0.41500455,  0.09565602],\n",
       "       [ 0.51051768,  1.24088543],\n",
       "       [ 0.70154394,  0.27184516],\n",
       "       [ 0.79705706,  1.38770971],\n",
       "       [ 1.94321462, -0.93211396],\n",
       "       [ 0.98808332,  0.12502088],\n",
       "       [-0.0625611 ,  1.97500684],\n",
       "       [-0.0625611 ,  0.27184516],\n",
       "       [ 0.22397829, -0.28608712],\n",
       "       [ 0.41500455, -0.46227625],\n",
       "       [ 1.27462271,  1.88691227],\n",
       "       [ 0.89257019,  1.27025028],\n",
       "       [-0.15807423,  1.62262856],\n",
       "       [ 0.03295203, -0.57973568],\n",
       "       [ 0.41500455,  0.00756145],\n",
       "       [ 0.12846516,  0.77104772],\n",
       "       [ 0.03295203, -0.57973568],\n",
       "       [ 1.08359645,  2.09246627],\n",
       "       [ 0.12846516,  0.27184516],\n",
       "       [ 0.12846516,  0.15438573],\n",
       "       [ 1.5611621 ,  1.00596657],\n",
       "       [-0.25358736, -0.4329114 ],\n",
       "       [ 0.70154394, -1.1083031 ],\n",
       "       [-0.15807423, -0.28608712],\n",
       "       [ 1.37013584,  2.0043717 ],\n",
       "       [ 1.46564897,  0.35993973],\n",
       "       [ 0.31949142, -0.52100597],\n",
       "       [ 0.98808332, -1.16703281],\n",
       "       [ 0.98808332,  1.7988177 ],\n",
       "       [ 0.31949142, -0.28608712],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 0.41500455,  0.15438573],\n",
       "       [-0.15807423,  1.41707457],\n",
       "       [ 0.89257019,  1.09406114],\n",
       "       [ 0.03295203, -0.55037082],\n",
       "       [ 0.98808332,  1.44643942],\n",
       "       [ 0.41500455, -0.13926283],\n",
       "       [ 0.22397829, -0.13926283],\n",
       "       [ 1.84770149, -0.28608712],\n",
       "       [-0.15807423, -0.46227625],\n",
       "       [ 1.94321462,  2.18056084],\n",
       "       [-0.25358736,  0.27184516],\n",
       "       [ 0.03295203, -0.4329114 ],\n",
       "       [ 0.12846516,  1.53453399],\n",
       "       [ 1.46564897,  1.00596657],\n",
       "       [-0.25358736,  0.15438573],\n",
       "       [ 0.03295203, -0.13926283],\n",
       "       [ 0.89257019, -0.55037082],\n",
       "       [ 0.89257019,  1.03533143],\n",
       "       [ 0.31949142, -0.19799255],\n",
       "       [ 1.46564897,  0.06629116],\n",
       "       [ 1.5611621 ,  1.123426  ],\n",
       "       [ 0.12846516,  0.21311545],\n",
       "       [ 0.03295203, -0.25672226],\n",
       "       [ 0.03295203,  1.27025028],\n",
       "       [-0.0625611 ,  0.15438573],\n",
       "       [ 0.41500455,  0.59485858],\n",
       "       [-0.0625611 , -0.37418169],\n",
       "       [-0.15807423,  0.85914229],\n",
       "       [ 2.13424088, -1.04957339],\n",
       "       [ 1.5611621 ,  0.00756145],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 0.22397829,  0.03692631],\n",
       "       [ 0.41500455, -0.46227625],\n",
       "       [ 0.51051768,  1.74008799],\n",
       "       [ 1.46564897, -1.04957339],\n",
       "       [ 0.89257019, -0.57973568],\n",
       "       [ 0.41500455,  0.27184516],\n",
       "       [ 0.41500455,  1.00596657],\n",
       "       [ 2.03872775, -1.19639767],\n",
       "       [ 1.94321462, -0.66783025],\n",
       "       [ 0.79705706,  0.53612887],\n",
       "       [ 0.03295203,  0.03692631],\n",
       "       [ 1.5611621 , -1.28449224],\n",
       "       [ 2.13424088, -0.69719511],\n",
       "       [ 2.13424088,  0.38930459],\n",
       "       [ 0.12846516,  0.09565602],\n",
       "       [ 2.03872775,  1.76945285],\n",
       "       [-0.0625611 ,  0.30121002],\n",
       "       [ 0.79705706, -1.1083031 ],\n",
       "       [ 0.79705706,  0.12502088],\n",
       "       [ 0.41500455, -0.49164111],\n",
       "       [ 0.31949142,  0.50676401],\n",
       "       [ 1.94321462, -1.37258681],\n",
       "       [ 0.41500455, -0.16862769],\n",
       "       [ 0.98808332, -1.07893824],\n",
       "       [ 0.60603081,  2.03373655],\n",
       "       [ 1.08359645, -1.22576253],\n",
       "       [ 1.84770149, -1.07893824],\n",
       "       [ 1.75218836, -0.28608712],\n",
       "       [ 1.08359645, -0.9027491 ],\n",
       "       [ 0.12846516,  0.03692631],\n",
       "       [ 0.89257019, -1.04957339],\n",
       "       [ 0.98808332, -1.02020853],\n",
       "       [ 0.98808332, -1.07893824],\n",
       "       [ 0.89257019, -1.37258681],\n",
       "       [ 0.70154394, -0.72655996],\n",
       "       [ 2.13424088, -0.81465453],\n",
       "       [ 0.12846516, -0.31545197],\n",
       "       [ 0.79705706, -0.84401939],\n",
       "       [ 1.27462271, -1.37258681],\n",
       "       [ 1.17910958, -1.46068138],\n",
       "       [-0.15807423, -1.07893824],\n",
       "       [ 1.08359645, -0.99084367]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b685efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d015fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f52615a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55271a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 2), (80, 2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9611d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320,), (80,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6846aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38cf408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# here is 4 layers:  1 is input, 2 hidden layers, 1 is output \n",
    "model.add(Dense(10, activation='relu', input_dim=2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "162b1d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 10)                30        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151 (604.00 Byte)\n",
      "Trainable params: 151 (604.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392c5e1",
   "metadata": {},
   "source": [
    "# Batch_Size Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e15f7252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 5170.2432 - accuracy: 0.3469\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4474.4570 - accuracy: 0.3469\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3976.3157 - accuracy: 0.3469\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3562.9343 - accuracy: 0.3469\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3198.6008 - accuracy: 0.3469\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2866.7791 - accuracy: 0.3469\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2558.2642 - accuracy: 0.3469\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2267.3386 - accuracy: 0.3469\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1990.1761 - accuracy: 0.3469\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1724.0756 - accuracy: 0.3469\n",
      "Run_Time: 0.8874478340148926\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics='accuracy')\n",
    "# this is classification problem that's why loss function is binary_crossentropy\n",
    "start = time.time()\n",
    "histroy = model.fit(X_train, y_train, epochs=10, batch_size=320)\n",
    "\"\"\"\n",
    "batch_size=320 it's mean my X_train number of rows, if i take batch_size=320 then it will become a\n",
    "batch_size, or if we take batch_size=1 then it will become a stochastic gradient descent.\n",
    "\"\"\"\n",
    "print(f'Run_Time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc997a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now Look we use batch_size=320 it's mean it's batch_size gradient decent\n",
    "and it's updated just 1 time into each Epoch and se the Run_Time: 0.8874478340148926 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478cb91",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c7267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 137.9872 - accuracy: 0.5562\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 126.3201 - accuracy: 0.5281\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 125.3740 - accuracy: 0.5281\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 136.0777 - accuracy: 0.4875\n",
      "Epoch 5/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 120.4416 - accuracy: 0.5406\n",
      "Epoch 6/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 122.1698 - accuracy: 0.5125\n",
      "Epoch 7/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 127.4143 - accuracy: 0.4656\n",
      "Epoch 8/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 116.7750 - accuracy: 0.5531\n",
      "Epoch 9/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 112.2758 - accuracy: 0.5469\n",
      "Epoch 10/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 122.2518 - accuracy: 0.4875\n",
      "Run_Time: 7.3454389572143555\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics='accuracy')\n",
    "start = time.time()\n",
    "histroy = model.fit(X_train, y_train, epochs=10, batch_size=1)\n",
    "print(f'Run_Time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df125984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Now Look we use Stochastic it's mean it's Stochastic gradient decent</br>\n",
    "and it's updated weight 320 time into each Epoch and se the Run_Time: 7.3454389572143555 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35923c03",
   "metadata": {},
   "source": [
    "### It's mean batch_size is faster than stochastic gradient decent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11da42f",
   "metadata": {},
   "source": [
    "<p>Now the question is who will move or converge towards the solution first ? mean who will reach correct values of weight and bias first </br>\n",
    "The answer is stochastic cause stochastic take more updated than batch_size.\n",
    "let's check \n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57980ec0",
   "metadata": {},
   "source": [
    "# Batch_Size Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cfa3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6806 - accuracy: 0.6313 - val_loss: 0.7487 - val_accuracy: 0.4125\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6744 - accuracy: 0.7063 - val_loss: 0.7477 - val_accuracy: 0.4250\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6701 - accuracy: 0.7500 - val_loss: 0.7471 - val_accuracy: 0.4250\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6666 - accuracy: 0.7844 - val_loss: 0.7466 - val_accuracy: 0.4500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6635 - accuracy: 0.7906 - val_loss: 0.7462 - val_accuracy: 0.4500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6608 - accuracy: 0.7969 - val_loss: 0.7457 - val_accuracy: 0.4500\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6582 - accuracy: 0.8000 - val_loss: 0.7453 - val_accuracy: 0.4500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6558 - accuracy: 0.8000 - val_loss: 0.7449 - val_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6535 - accuracy: 0.8000 - val_loss: 0.7444 - val_accuracy: 0.4625\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6513 - accuracy: 0.8031 - val_loss: 0.7440 - val_accuracy: 0.4625\n",
      "Run_Time: 1.6979470252990723\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics='accuracy')\n",
    "start = time.time()\n",
    "\"\"\"Here i am skiping Train_test_spiliting i will take X_scaled it's mean 400 rows and y\"\"\"\n",
    "histroy = model.fit(X_scaled, y, epochs=10, batch_size=400, validation_split=0.2)\n",
    "print(f'Run_Time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e19e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_accuracy: 0.4625\n",
    "# Run_Time: 1.6979470252990723"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b929391",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fad33aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "320/320 [==============================] - 2s 3ms/step - loss: 0.5554 - accuracy: 0.7469 - val_loss: 0.7031 - val_accuracy: 0.4125\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.7531 - val_loss: 0.6093 - val_accuracy: 0.6500\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8500 - val_loss: 0.4984 - val_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3031 - accuracy: 0.8594 - val_loss: 0.4163 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2839 - accuracy: 0.8625 - val_loss: 0.3613 - val_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8625 - val_loss: 0.3157 - val_accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8625 - val_loss: 0.2953 - val_accuracy: 0.9125\n",
      "Epoch 8/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8687 - val_loss: 0.2659 - val_accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.8750 - val_loss: 0.2571 - val_accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.8719 - val_loss: 0.2447 - val_accuracy: 0.9500\n",
      "Run_Time: 9.379295110702515\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics='accuracy')\n",
    "start = time.time()\n",
    "\"\"\"Here i am skiping Train_test_spiliting i will take X_scaled it's mean 400 rows and y\"\"\"\n",
    "histroy = model.fit(X_scaled, y, epochs=10, batch_size=1, validation_split=0.2)\n",
    "print(f'Run_Time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6e233ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_accuracy: 0.9500\n",
    "# Run_Time: 9.379295110702515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "182f491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you see for batch_size it's run time low but accuracy also bad but\n",
    "# for the stochastic run time high but accuracy is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59110bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so over all we get from here that for time being batch_size is fatser\n",
    "# and for best solution stochastic is faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbc39e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see another example between batch_size and stochastic gradient decent let's increse the Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765eefd7",
   "metadata": {},
   "source": [
    "# Stochastics GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59cb9134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "320/320 [==============================] - 2s 3ms/step - loss: 0.2760 - accuracy: 0.8781 - val_loss: 0.2291 - val_accuracy: 0.9625\n",
      "Epoch 2/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8750 - val_loss: 0.2199 - val_accuracy: 0.9625\n",
      "Epoch 3/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.8781 - val_loss: 0.2194 - val_accuracy: 0.9750\n",
      "Epoch 4/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.8781 - val_loss: 0.2034 - val_accuracy: 0.9750\n",
      "Epoch 5/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8781 - val_loss: 0.1983 - val_accuracy: 0.9750\n",
      "Epoch 6/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8750 - val_loss: 0.1942 - val_accuracy: 0.9750\n",
      "Epoch 7/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8844 - val_loss: 0.1938 - val_accuracy: 0.9750\n",
      "Epoch 8/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8875 - val_loss: 0.1982 - val_accuracy: 0.9625\n",
      "Epoch 9/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.8813 - val_loss: 0.1884 - val_accuracy: 0.9625\n",
      "Epoch 10/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8875 - val_loss: 0.1845 - val_accuracy: 0.9750\n",
      "Epoch 11/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8844 - val_loss: 0.1822 - val_accuracy: 0.9625\n",
      "Epoch 12/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.8844 - val_loss: 0.1777 - val_accuracy: 0.9750\n",
      "Epoch 13/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.8875 - val_loss: 0.1743 - val_accuracy: 0.9750\n",
      "Epoch 14/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8813 - val_loss: 0.1688 - val_accuracy: 0.9750\n",
      "Epoch 15/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.8938 - val_loss: 0.1754 - val_accuracy: 0.9625\n",
      "Epoch 16/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8844 - val_loss: 0.1712 - val_accuracy: 0.9625\n",
      "Epoch 17/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.8844 - val_loss: 0.1725 - val_accuracy: 0.9625\n",
      "Epoch 18/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8844 - val_loss: 0.1708 - val_accuracy: 0.9625\n",
      "Epoch 19/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8875 - val_loss: 0.1743 - val_accuracy: 0.9625\n",
      "Epoch 20/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8906 - val_loss: 0.1619 - val_accuracy: 0.9625\n",
      "Epoch 21/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8938 - val_loss: 0.1604 - val_accuracy: 0.9625\n",
      "Epoch 22/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8906 - val_loss: 0.1587 - val_accuracy: 0.9625\n",
      "Epoch 23/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.8906 - val_loss: 0.1592 - val_accuracy: 0.9625\n",
      "Epoch 24/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.9031 - val_loss: 0.1670 - val_accuracy: 0.9625\n",
      "Epoch 25/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8938 - val_loss: 0.1634 - val_accuracy: 0.9625\n",
      "Epoch 26/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8906 - val_loss: 0.1626 - val_accuracy: 0.9625\n",
      "Epoch 27/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8969 - val_loss: 0.1581 - val_accuracy: 0.9625\n",
      "Epoch 28/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.9000 - val_loss: 0.1593 - val_accuracy: 0.9625\n",
      "Epoch 29/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.8938 - val_loss: 0.1621 - val_accuracy: 0.9625\n",
      "Epoch 30/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.9031 - val_loss: 0.1721 - val_accuracy: 0.9750\n",
      "Epoch 31/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.8938 - val_loss: 0.1711 - val_accuracy: 0.9750\n",
      "Epoch 32/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8906 - val_loss: 0.1717 - val_accuracy: 0.9750\n",
      "Epoch 33/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.9000 - val_loss: 0.1681 - val_accuracy: 0.9750\n",
      "Epoch 34/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.8969 - val_loss: 0.1700 - val_accuracy: 0.9750\n",
      "Epoch 35/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.9031 - val_loss: 0.1655 - val_accuracy: 0.9750\n",
      "Epoch 36/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8969 - val_loss: 0.1572 - val_accuracy: 0.9625\n",
      "Epoch 37/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2788 - accuracy: 0.9062 - val_loss: 0.1677 - val_accuracy: 0.9750\n",
      "Epoch 38/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.9031 - val_loss: 0.1698 - val_accuracy: 0.9500\n",
      "Epoch 39/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.9000 - val_loss: 0.1692 - val_accuracy: 0.9750\n",
      "Epoch 40/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2741 - accuracy: 0.9062 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
      "Epoch 41/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.9031 - val_loss: 0.1678 - val_accuracy: 0.9750\n",
      "Epoch 42/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.9031 - val_loss: 0.1691 - val_accuracy: 0.9625\n",
      "Epoch 43/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.9062 - val_loss: 0.1633 - val_accuracy: 0.9750\n",
      "Epoch 44/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9062 - val_loss: 0.1536 - val_accuracy: 0.9750\n",
      "Epoch 45/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.9062 - val_loss: 0.1514 - val_accuracy: 0.9750\n",
      "Epoch 46/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.9031 - val_loss: 0.1557 - val_accuracy: 0.9750\n",
      "Epoch 47/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9031 - val_loss: 0.1636 - val_accuracy: 0.9500\n",
      "Epoch 48/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.9062 - val_loss: 0.1584 - val_accuracy: 0.9750\n",
      "Epoch 49/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9031 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
      "Epoch 50/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.9094 - val_loss: 0.1692 - val_accuracy: 0.9500\n",
      "Epoch 51/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.9062 - val_loss: 0.1651 - val_accuracy: 0.9500\n",
      "Epoch 52/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9062 - val_loss: 0.1679 - val_accuracy: 0.9500\n",
      "Epoch 53/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9062 - val_loss: 0.1703 - val_accuracy: 0.9500\n",
      "Epoch 54/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.9062 - val_loss: 0.1675 - val_accuracy: 0.9625\n",
      "Epoch 55/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.9062 - val_loss: 0.1666 - val_accuracy: 0.9625\n",
      "Epoch 56/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2727 - accuracy: 0.9031 - val_loss: 0.1658 - val_accuracy: 0.9625\n",
      "Epoch 57/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2749 - accuracy: 0.9062 - val_loss: 0.1684 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.9062 - val_loss: 0.1628 - val_accuracy: 0.9500\n",
      "Epoch 59/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.9000 - val_loss: 0.1636 - val_accuracy: 0.9625\n",
      "Epoch 60/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9062 - val_loss: 0.1689 - val_accuracy: 0.9500\n",
      "Epoch 61/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.9000 - val_loss: 0.1639 - val_accuracy: 0.9500\n",
      "Epoch 62/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.9062 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
      "Epoch 63/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9062 - val_loss: 0.1653 - val_accuracy: 0.9500\n",
      "Epoch 64/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.9125 - val_loss: 0.1677 - val_accuracy: 0.9500\n",
      "Epoch 65/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9031 - val_loss: 0.1654 - val_accuracy: 0.9500\n",
      "Epoch 66/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2720 - accuracy: 0.9062 - val_loss: 0.1725 - val_accuracy: 0.9500\n",
      "Epoch 67/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9031 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
      "Epoch 68/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.9062 - val_loss: 0.1668 - val_accuracy: 0.9500\n",
      "Epoch 69/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.9094 - val_loss: 0.1695 - val_accuracy: 0.9500\n",
      "Epoch 70/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.9062 - val_loss: 0.1720 - val_accuracy: 0.9500\n",
      "Epoch 71/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9125 - val_loss: 0.1689 - val_accuracy: 0.9500\n",
      "Epoch 72/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9094 - val_loss: 0.1667 - val_accuracy: 0.9500\n",
      "Epoch 73/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.9125 - val_loss: 0.1640 - val_accuracy: 0.9500\n",
      "Epoch 74/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.9094 - val_loss: 0.1676 - val_accuracy: 0.9500\n",
      "Epoch 75/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9125 - val_loss: 0.1757 - val_accuracy: 0.9375\n",
      "Epoch 76/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.9125 - val_loss: 0.1671 - val_accuracy: 0.9500\n",
      "Epoch 77/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.9094 - val_loss: 0.1703 - val_accuracy: 0.9500\n",
      "Epoch 78/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.9125 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Epoch 79/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.9156 - val_loss: 0.1711 - val_accuracy: 0.9500\n",
      "Epoch 80/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.9125 - val_loss: 0.1796 - val_accuracy: 0.9375\n",
      "Epoch 81/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9156 - val_loss: 0.1744 - val_accuracy: 0.9500\n",
      "Epoch 82/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.9156 - val_loss: 0.1693 - val_accuracy: 0.9500\n",
      "Epoch 83/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.9125 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
      "Epoch 84/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9156 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
      "Epoch 85/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.9156 - val_loss: 0.1710 - val_accuracy: 0.9500\n",
      "Epoch 86/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.9156 - val_loss: 0.1772 - val_accuracy: 0.9375\n",
      "Epoch 87/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.9125 - val_loss: 0.1644 - val_accuracy: 0.9500\n",
      "Epoch 88/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.9156 - val_loss: 0.1575 - val_accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9125 - val_loss: 0.1710 - val_accuracy: 0.9375\n",
      "Epoch 90/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.9031 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
      "Epoch 91/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.9156 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Epoch 92/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.9156 - val_loss: 0.1787 - val_accuracy: 0.9375\n",
      "Epoch 93/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.9156 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
      "Epoch 94/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9156 - val_loss: 0.1655 - val_accuracy: 0.9500\n",
      "Epoch 95/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9156 - val_loss: 0.1603 - val_accuracy: 0.9500\n",
      "Epoch 96/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.9125 - val_loss: 0.1731 - val_accuracy: 0.9375\n",
      "Epoch 97/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.9156 - val_loss: 0.1677 - val_accuracy: 0.9500\n",
      "Epoch 98/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9125 - val_loss: 0.1762 - val_accuracy: 0.9375\n",
      "Epoch 99/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.9156 - val_loss: 0.1800 - val_accuracy: 0.9375\n",
      "Epoch 100/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.9094 - val_loss: 0.1647 - val_accuracy: 0.9500\n",
      "Epoch 101/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.9094 - val_loss: 0.1726 - val_accuracy: 0.9375\n",
      "Epoch 102/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9156 - val_loss: 0.1776 - val_accuracy: 0.9375\n",
      "Epoch 103/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.9125 - val_loss: 0.1685 - val_accuracy: 0.9500\n",
      "Epoch 104/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9156 - val_loss: 0.1763 - val_accuracy: 0.9375\n",
      "Epoch 105/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2795 - accuracy: 0.9156 - val_loss: 0.1823 - val_accuracy: 0.9375\n",
      "Epoch 106/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9125 - val_loss: 0.1769 - val_accuracy: 0.9375\n",
      "Epoch 107/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9125 - val_loss: 0.1820 - val_accuracy: 0.9375\n",
      "Epoch 108/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.9125 - val_loss: 0.1794 - val_accuracy: 0.9375\n",
      "Epoch 109/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.9125 - val_loss: 0.1770 - val_accuracy: 0.9375\n",
      "Epoch 110/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.9156 - val_loss: 0.1794 - val_accuracy: 0.9375\n",
      "Epoch 111/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.9125 - val_loss: 0.1725 - val_accuracy: 0.9500\n",
      "Epoch 112/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.9156 - val_loss: 0.1805 - val_accuracy: 0.9375\n",
      "Epoch 113/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.9125 - val_loss: 0.1801 - val_accuracy: 0.9375\n",
      "Epoch 114/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9125 - val_loss: 0.1827 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.9125 - val_loss: 0.1848 - val_accuracy: 0.9375\n",
      "Epoch 116/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2844 - accuracy: 0.9125 - val_loss: 0.1775 - val_accuracy: 0.9375\n",
      "Epoch 117/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.9156 - val_loss: 0.1816 - val_accuracy: 0.9375\n",
      "Epoch 118/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.9125 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
      "Epoch 119/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.9125 - val_loss: 0.1871 - val_accuracy: 0.9375\n",
      "Epoch 120/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.9125 - val_loss: 0.1859 - val_accuracy: 0.9375\n",
      "Epoch 121/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9094 - val_loss: 0.1860 - val_accuracy: 0.9375\n",
      "Epoch 122/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.9094 - val_loss: 0.1928 - val_accuracy: 0.9375\n",
      "Epoch 123/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.9125 - val_loss: 0.1948 - val_accuracy: 0.9375\n",
      "Epoch 124/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.9125 - val_loss: 0.2015 - val_accuracy: 0.9375\n",
      "Epoch 125/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9125 - val_loss: 0.1855 - val_accuracy: 0.9375\n",
      "Epoch 126/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.9125 - val_loss: 0.1913 - val_accuracy: 0.9375\n",
      "Epoch 127/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.9125 - val_loss: 0.1955 - val_accuracy: 0.9250\n",
      "Epoch 128/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.9125 - val_loss: 0.1828 - val_accuracy: 0.9375\n",
      "Epoch 129/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.9125 - val_loss: 0.1861 - val_accuracy: 0.9375\n",
      "Epoch 130/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9094 - val_loss: 0.1858 - val_accuracy: 0.9375\n",
      "Epoch 131/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.9094 - val_loss: 0.1920 - val_accuracy: 0.9375\n",
      "Epoch 132/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9094 - val_loss: 0.1916 - val_accuracy: 0.9375\n",
      "Epoch 133/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.9094 - val_loss: 0.1989 - val_accuracy: 0.9250\n",
      "Epoch 134/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9062 - val_loss: 0.1851 - val_accuracy: 0.9375\n",
      "Epoch 135/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2873 - accuracy: 0.9125 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
      "Epoch 136/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.9125 - val_loss: 0.1785 - val_accuracy: 0.9500\n",
      "Epoch 137/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.9062 - val_loss: 0.1700 - val_accuracy: 0.9500\n",
      "Epoch 138/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.9125 - val_loss: 0.1835 - val_accuracy: 0.9375\n",
      "Epoch 139/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.9062 - val_loss: 0.1768 - val_accuracy: 0.9375\n",
      "Epoch 140/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.9094 - val_loss: 0.1845 - val_accuracy: 0.9375\n",
      "Epoch 141/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.9094 - val_loss: 0.1881 - val_accuracy: 0.9375\n",
      "Epoch 142/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.9062 - val_loss: 0.1858 - val_accuracy: 0.9375\n",
      "Epoch 143/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.9125 - val_loss: 0.1886 - val_accuracy: 0.9375\n",
      "Epoch 144/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9094 - val_loss: 0.1831 - val_accuracy: 0.9375\n",
      "Epoch 145/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.9125 - val_loss: 0.1926 - val_accuracy: 0.9375\n",
      "Epoch 146/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9062 - val_loss: 0.1767 - val_accuracy: 0.9500\n",
      "Epoch 147/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9125 - val_loss: 0.1867 - val_accuracy: 0.9375\n",
      "Epoch 148/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2808 - accuracy: 0.9125 - val_loss: 0.1969 - val_accuracy: 0.9375\n",
      "Epoch 149/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9125 - val_loss: 0.1937 - val_accuracy: 0.9375\n",
      "Epoch 150/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.9094 - val_loss: 0.1913 - val_accuracy: 0.9375\n",
      "Epoch 151/500\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2804 - accuracy: 0.9062 - val_loss: 0.1994 - val_accuracy: 0.9375\n",
      "Epoch 152/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9094 - val_loss: 0.1977 - val_accuracy: 0.9375\n",
      "Epoch 153/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.9062 - val_loss: 0.1942 - val_accuracy: 0.9375\n",
      "Epoch 154/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9062 - val_loss: 0.1896 - val_accuracy: 0.9375\n",
      "Epoch 155/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.9062 - val_loss: 0.1879 - val_accuracy: 0.9375\n",
      "Epoch 156/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9062 - val_loss: 0.1768 - val_accuracy: 0.9375\n",
      "Epoch 157/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.9094 - val_loss: 0.1942 - val_accuracy: 0.9375\n",
      "Epoch 158/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2929 - accuracy: 0.9094 - val_loss: 0.1851 - val_accuracy: 0.9375\n",
      "Epoch 159/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2858 - accuracy: 0.9062 - val_loss: 0.1996 - val_accuracy: 0.9250\n",
      "Epoch 160/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.9094 - val_loss: 0.1972 - val_accuracy: 0.9375\n",
      "Epoch 161/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.9062 - val_loss: 0.2074 - val_accuracy: 0.9250\n",
      "Epoch 162/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.9062 - val_loss: 0.2047 - val_accuracy: 0.9125\n",
      "Epoch 163/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.8969 - val_loss: 0.1985 - val_accuracy: 0.9250\n",
      "Epoch 164/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.9062 - val_loss: 0.1832 - val_accuracy: 0.9375\n",
      "Epoch 165/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.9125 - val_loss: 0.1881 - val_accuracy: 0.9375\n",
      "Epoch 166/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2839 - accuracy: 0.9000 - val_loss: 0.1938 - val_accuracy: 0.9250\n",
      "Epoch 167/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.9062 - val_loss: 0.2087 - val_accuracy: 0.9000\n",
      "Epoch 168/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.9094 - val_loss: 0.1838 - val_accuracy: 0.9375\n",
      "Epoch 169/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.9062 - val_loss: 0.1973 - val_accuracy: 0.9250\n",
      "Epoch 170/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.9125 - val_loss: 0.1954 - val_accuracy: 0.9125\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.9094 - val_loss: 0.1908 - val_accuracy: 0.9375\n",
      "Epoch 172/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.9031 - val_loss: 0.1994 - val_accuracy: 0.9125\n",
      "Epoch 173/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.9031 - val_loss: 0.1946 - val_accuracy: 0.9250\n",
      "Epoch 174/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.9062 - val_loss: 0.1812 - val_accuracy: 0.9375\n",
      "Epoch 175/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9031 - val_loss: 0.1796 - val_accuracy: 0.9500\n",
      "Epoch 176/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9094 - val_loss: 0.1938 - val_accuracy: 0.9375\n",
      "Epoch 177/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.9031 - val_loss: 0.1804 - val_accuracy: 0.9375\n",
      "Epoch 178/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9062 - val_loss: 0.1786 - val_accuracy: 0.9375\n",
      "Epoch 179/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9062 - val_loss: 0.1836 - val_accuracy: 0.9250\n",
      "Epoch 180/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9125 - val_loss: 0.1775 - val_accuracy: 0.9375\n",
      "Epoch 181/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.9062 - val_loss: 0.1871 - val_accuracy: 0.9250\n",
      "Epoch 182/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9031 - val_loss: 0.1898 - val_accuracy: 0.9250\n",
      "Epoch 183/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.9094 - val_loss: 0.1996 - val_accuracy: 0.9125\n",
      "Epoch 184/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2890 - accuracy: 0.9031 - val_loss: 0.1700 - val_accuracy: 0.9375\n",
      "Epoch 185/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9094 - val_loss: 0.1818 - val_accuracy: 0.9250\n",
      "Epoch 186/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.9031 - val_loss: 0.1860 - val_accuracy: 0.9250\n",
      "Epoch 187/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.9094 - val_loss: 0.1921 - val_accuracy: 0.9125\n",
      "Epoch 188/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2893 - accuracy: 0.9062 - val_loss: 0.1888 - val_accuracy: 0.9250\n",
      "Epoch 189/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2801 - accuracy: 0.9031 - val_loss: 0.2019 - val_accuracy: 0.9000\n",
      "Epoch 190/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.9031 - val_loss: 0.1766 - val_accuracy: 0.9375\n",
      "Epoch 191/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.9031 - val_loss: 0.1914 - val_accuracy: 0.9375\n",
      "Epoch 192/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9062 - val_loss: 0.1826 - val_accuracy: 0.9250\n",
      "Epoch 193/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2904 - accuracy: 0.9031 - val_loss: 0.1884 - val_accuracy: 0.9250\n",
      "Epoch 194/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.9062 - val_loss: 0.1932 - val_accuracy: 0.9250\n",
      "Epoch 195/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.9031 - val_loss: 0.1840 - val_accuracy: 0.9375\n",
      "Epoch 196/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.9125 - val_loss: 0.1908 - val_accuracy: 0.9375\n",
      "Epoch 197/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.9125 - val_loss: 0.2027 - val_accuracy: 0.9125\n",
      "Epoch 198/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.9062 - val_loss: 0.1966 - val_accuracy: 0.9250\n",
      "Epoch 199/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9094 - val_loss: 0.1967 - val_accuracy: 0.9125\n",
      "Epoch 200/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9031 - val_loss: 0.2076 - val_accuracy: 0.9000\n",
      "Epoch 201/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9125 - val_loss: 0.2004 - val_accuracy: 0.9250\n",
      "Epoch 202/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.9062 - val_loss: 0.2077 - val_accuracy: 0.9125\n",
      "Epoch 203/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9062 - val_loss: 0.2020 - val_accuracy: 0.9250\n",
      "Epoch 204/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9094 - val_loss: 0.1911 - val_accuracy: 0.9375\n",
      "Epoch 205/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.9094 - val_loss: 0.1777 - val_accuracy: 0.9500\n",
      "Epoch 206/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.9156 - val_loss: 0.1952 - val_accuracy: 0.9250\n",
      "Epoch 207/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.9187 - val_loss: 0.1829 - val_accuracy: 0.9500\n",
      "Epoch 208/500\n",
      "320/320 [==============================] - 1s 5ms/step - loss: 0.2773 - accuracy: 0.9187 - val_loss: 0.1890 - val_accuracy: 0.9375\n",
      "Epoch 209/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9125 - val_loss: 0.1837 - val_accuracy: 0.9375\n",
      "Epoch 210/500\n",
      "320/320 [==============================] - 1s 5ms/step - loss: 0.2826 - accuracy: 0.9125 - val_loss: 0.2131 - val_accuracy: 0.9125\n",
      "Epoch 211/500\n",
      "320/320 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.9094 - val_loss: 0.1981 - val_accuracy: 0.9250\n",
      "Epoch 212/500\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.2882 - accuracy: 0.9156 - val_loss: 0.1851 - val_accuracy: 0.9375\n",
      "Epoch 213/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9219 - val_loss: 0.1916 - val_accuracy: 0.9375\n",
      "Epoch 214/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.9187 - val_loss: 0.2193 - val_accuracy: 0.9000\n",
      "Epoch 215/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.9125 - val_loss: 0.2404 - val_accuracy: 0.9000\n",
      "Epoch 216/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.9094 - val_loss: 0.2048 - val_accuracy: 0.9250\n",
      "Epoch 217/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.9187 - val_loss: 0.1795 - val_accuracy: 0.9500\n",
      "Epoch 218/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.9187 - val_loss: 0.1878 - val_accuracy: 0.9375\n",
      "Epoch 219/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.9156 - val_loss: 0.2144 - val_accuracy: 0.9000\n",
      "Epoch 220/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.9031 - val_loss: 0.2334 - val_accuracy: 0.9000\n",
      "Epoch 221/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.9031 - val_loss: 0.1975 - val_accuracy: 0.9250\n",
      "Epoch 222/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9125 - val_loss: 0.1966 - val_accuracy: 0.9250\n",
      "Epoch 223/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9219 - val_loss: 0.1869 - val_accuracy: 0.9375\n",
      "Epoch 224/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.9125 - val_loss: 0.1750 - val_accuracy: 0.9500\n",
      "Epoch 225/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.9125 - val_loss: 0.1814 - val_accuracy: 0.9375\n",
      "Epoch 226/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9187 - val_loss: 0.1928 - val_accuracy: 0.9375\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9156 - val_loss: 0.1912 - val_accuracy: 0.9375\n",
      "Epoch 228/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2815 - accuracy: 0.9187 - val_loss: 0.2031 - val_accuracy: 0.9375\n",
      "Epoch 229/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.9156 - val_loss: 0.1975 - val_accuracy: 0.9375\n",
      "Epoch 230/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.9187 - val_loss: 0.1873 - val_accuracy: 0.9375\n",
      "Epoch 231/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9125 - val_loss: 0.1811 - val_accuracy: 0.9375\n",
      "Epoch 232/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.9187 - val_loss: 0.2103 - val_accuracy: 0.9125\n",
      "Epoch 233/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.9187 - val_loss: 0.2061 - val_accuracy: 0.9250\n",
      "Epoch 234/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2851 - accuracy: 0.9156 - val_loss: 0.2146 - val_accuracy: 0.9125\n",
      "Epoch 235/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.9094 - val_loss: 0.1801 - val_accuracy: 0.9500\n",
      "Epoch 236/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9156 - val_loss: 0.1968 - val_accuracy: 0.9250\n",
      "Epoch 237/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.9187 - val_loss: 0.2048 - val_accuracy: 0.9250\n",
      "Epoch 238/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.9187 - val_loss: 0.1971 - val_accuracy: 0.9375\n",
      "Epoch 239/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.9125 - val_loss: 0.2096 - val_accuracy: 0.9250\n",
      "Epoch 240/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9156 - val_loss: 0.2207 - val_accuracy: 0.9000\n",
      "Epoch 241/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2778 - accuracy: 0.9094 - val_loss: 0.1992 - val_accuracy: 0.9375\n",
      "Epoch 242/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2768 - accuracy: 0.9125 - val_loss: 0.2212 - val_accuracy: 0.9125\n",
      "Epoch 243/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.9156 - val_loss: 0.2038 - val_accuracy: 0.9250\n",
      "Epoch 244/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.9187 - val_loss: 0.1997 - val_accuracy: 0.9375\n",
      "Epoch 245/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.9156 - val_loss: 0.2113 - val_accuracy: 0.9375\n",
      "Epoch 246/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9156 - val_loss: 0.2112 - val_accuracy: 0.9250\n",
      "Epoch 247/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.9156 - val_loss: 0.2267 - val_accuracy: 0.9125\n",
      "Epoch 248/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.9062 - val_loss: 0.1867 - val_accuracy: 0.9375\n",
      "Epoch 249/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.9187 - val_loss: 0.2011 - val_accuracy: 0.9375\n",
      "Epoch 250/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.9187 - val_loss: 0.2081 - val_accuracy: 0.9375\n",
      "Epoch 251/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.9156 - val_loss: 0.2230 - val_accuracy: 0.9250\n",
      "Epoch 252/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9094 - val_loss: 0.2169 - val_accuracy: 0.9250\n",
      "Epoch 253/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.9125 - val_loss: 0.2187 - val_accuracy: 0.9250\n",
      "Epoch 254/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.9031 - val_loss: 0.2078 - val_accuracy: 0.9375\n",
      "Epoch 255/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.9156 - val_loss: 0.2070 - val_accuracy: 0.9375\n",
      "Epoch 256/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9156 - val_loss: 0.2283 - val_accuracy: 0.9125\n",
      "Epoch 257/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.9062 - val_loss: 0.2179 - val_accuracy: 0.9125\n",
      "Epoch 258/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.9156 - val_loss: 0.2068 - val_accuracy: 0.9250\n",
      "Epoch 259/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9219 - val_loss: 0.1911 - val_accuracy: 0.9500\n",
      "Epoch 260/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.9187 - val_loss: 0.1932 - val_accuracy: 0.9500\n",
      "Epoch 261/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.9094 - val_loss: 0.1969 - val_accuracy: 0.9375\n",
      "Epoch 262/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9156 - val_loss: 0.1995 - val_accuracy: 0.9375\n",
      "Epoch 263/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.9156 - val_loss: 0.1890 - val_accuracy: 0.9375\n",
      "Epoch 264/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.9187 - val_loss: 0.2040 - val_accuracy: 0.9375\n",
      "Epoch 265/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.9125 - val_loss: 0.1903 - val_accuracy: 0.9500\n",
      "Epoch 266/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.9156 - val_loss: 0.2016 - val_accuracy: 0.9375\n",
      "Epoch 267/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.9156 - val_loss: 0.2027 - val_accuracy: 0.9500\n",
      "Epoch 268/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.9156 - val_loss: 0.2059 - val_accuracy: 0.9375\n",
      "Epoch 269/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2705 - accuracy: 0.9156 - val_loss: 0.1916 - val_accuracy: 0.9500\n",
      "Epoch 270/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.9156 - val_loss: 0.2138 - val_accuracy: 0.9375\n",
      "Epoch 271/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9156 - val_loss: 0.1984 - val_accuracy: 0.9500\n",
      "Epoch 272/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.9156 - val_loss: 0.1896 - val_accuracy: 0.9500\n",
      "Epoch 273/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.9062 - val_loss: 0.2212 - val_accuracy: 0.9250\n",
      "Epoch 274/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.9156 - val_loss: 0.2028 - val_accuracy: 0.9375\n",
      "Epoch 275/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.9156 - val_loss: 0.1940 - val_accuracy: 0.9500\n",
      "Epoch 276/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.9125 - val_loss: 0.1952 - val_accuracy: 0.9500\n",
      "Epoch 277/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9156 - val_loss: 0.1983 - val_accuracy: 0.9500\n",
      "Epoch 278/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9125 - val_loss: 0.2023 - val_accuracy: 0.9500\n",
      "Epoch 279/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.9125 - val_loss: 0.2133 - val_accuracy: 0.9375\n",
      "Epoch 280/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9156 - val_loss: 0.2297 - val_accuracy: 0.9250\n",
      "Epoch 281/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.9156 - val_loss: 0.2008 - val_accuracy: 0.9500\n",
      "Epoch 282/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9156 - val_loss: 0.2326 - val_accuracy: 0.9125\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.9156 - val_loss: 0.2080 - val_accuracy: 0.9375\n",
      "Epoch 284/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.9125 - val_loss: 0.2079 - val_accuracy: 0.9375\n",
      "Epoch 285/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9187 - val_loss: 0.2145 - val_accuracy: 0.9250\n",
      "Epoch 286/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.9187 - val_loss: 0.2158 - val_accuracy: 0.9125\n",
      "Epoch 287/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.9094 - val_loss: 0.2218 - val_accuracy: 0.9125\n",
      "Epoch 288/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2746 - accuracy: 0.9156 - val_loss: 0.2139 - val_accuracy: 0.9250\n",
      "Epoch 289/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.9156 - val_loss: 0.2052 - val_accuracy: 0.9375\n",
      "Epoch 290/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9125 - val_loss: 0.2238 - val_accuracy: 0.9250\n",
      "Epoch 291/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.9156 - val_loss: 0.1953 - val_accuracy: 0.9500\n",
      "Epoch 292/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.9125 - val_loss: 0.2072 - val_accuracy: 0.9375\n",
      "Epoch 293/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.9156 - val_loss: 0.2209 - val_accuracy: 0.9250\n",
      "Epoch 294/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9187 - val_loss: 0.2067 - val_accuracy: 0.9375\n",
      "Epoch 295/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9156 - val_loss: 0.2009 - val_accuracy: 0.9500\n",
      "Epoch 296/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2808 - accuracy: 0.9156 - val_loss: 0.2167 - val_accuracy: 0.9375\n",
      "Epoch 297/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.9187 - val_loss: 0.1965 - val_accuracy: 0.9500\n",
      "Epoch 298/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9156 - val_loss: 0.2002 - val_accuracy: 0.9500\n",
      "Epoch 299/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.9125 - val_loss: 0.1967 - val_accuracy: 0.9500\n",
      "Epoch 300/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.9125 - val_loss: 0.2089 - val_accuracy: 0.9375\n",
      "Epoch 301/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.9187 - val_loss: 0.1929 - val_accuracy: 0.9500\n",
      "Epoch 302/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2728 - accuracy: 0.9094 - val_loss: 0.2291 - val_accuracy: 0.9125\n",
      "Epoch 303/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9125 - val_loss: 0.2265 - val_accuracy: 0.9125\n",
      "Epoch 304/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.9125 - val_loss: 0.1801 - val_accuracy: 0.9500\n",
      "Epoch 305/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.9156 - val_loss: 0.1960 - val_accuracy: 0.9500\n",
      "Epoch 306/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.9156 - val_loss: 0.2019 - val_accuracy: 0.9375\n",
      "Epoch 307/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.9156 - val_loss: 0.2143 - val_accuracy: 0.9250\n",
      "Epoch 308/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2868 - accuracy: 0.9156 - val_loss: 0.2155 - val_accuracy: 0.9375\n",
      "Epoch 309/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.9156 - val_loss: 0.1948 - val_accuracy: 0.9500\n",
      "Epoch 310/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2778 - accuracy: 0.9125 - val_loss: 0.1824 - val_accuracy: 0.9500\n",
      "Epoch 311/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.9156 - val_loss: 0.2163 - val_accuracy: 0.9250\n",
      "Epoch 312/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2868 - accuracy: 0.9156 - val_loss: 0.2127 - val_accuracy: 0.9250\n",
      "Epoch 313/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2858 - accuracy: 0.9094 - val_loss: 0.2005 - val_accuracy: 0.9500\n",
      "Epoch 314/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.9125 - val_loss: 0.2291 - val_accuracy: 0.9250\n",
      "Epoch 315/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.9125 - val_loss: 0.2218 - val_accuracy: 0.9250\n",
      "Epoch 316/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.9125 - val_loss: 0.2128 - val_accuracy: 0.9375\n",
      "Epoch 317/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.9156 - val_loss: 0.2102 - val_accuracy: 0.9375\n",
      "Epoch 318/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2805 - accuracy: 0.9094 - val_loss: 0.1980 - val_accuracy: 0.9500\n",
      "Epoch 319/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.9156 - val_loss: 0.2144 - val_accuracy: 0.9250\n",
      "Epoch 320/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.9156 - val_loss: 0.2049 - val_accuracy: 0.9375\n",
      "Epoch 321/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.9156 - val_loss: 0.2001 - val_accuracy: 0.9375\n",
      "Epoch 322/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.9094 - val_loss: 0.1871 - val_accuracy: 0.9500\n",
      "Epoch 323/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.9156 - val_loss: 0.1903 - val_accuracy: 0.9375\n",
      "Epoch 324/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.9156 - val_loss: 0.1783 - val_accuracy: 0.9500\n",
      "Epoch 325/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3000 - accuracy: 0.9156 - val_loss: 0.1894 - val_accuracy: 0.9500\n",
      "Epoch 326/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.9156 - val_loss: 0.1901 - val_accuracy: 0.9500\n",
      "Epoch 327/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.9156 - val_loss: 0.2102 - val_accuracy: 0.9375\n",
      "Epoch 328/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.9156 - val_loss: 0.2389 - val_accuracy: 0.9000\n",
      "Epoch 329/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.9156 - val_loss: 0.2054 - val_accuracy: 0.9500\n",
      "Epoch 330/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.9156 - val_loss: 0.2257 - val_accuracy: 0.9250\n",
      "Epoch 331/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.9156 - val_loss: 0.2020 - val_accuracy: 0.9500\n",
      "Epoch 332/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2808 - accuracy: 0.9125 - val_loss: 0.2281 - val_accuracy: 0.9250\n",
      "Epoch 333/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9156 - val_loss: 0.2163 - val_accuracy: 0.9375\n",
      "Epoch 334/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.9156 - val_loss: 0.2127 - val_accuracy: 0.9375\n",
      "Epoch 335/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.9156 - val_loss: 0.2133 - val_accuracy: 0.9500\n",
      "Epoch 336/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.9156 - val_loss: 0.2147 - val_accuracy: 0.9375\n",
      "Epoch 337/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.9125 - val_loss: 0.2077 - val_accuracy: 0.9500\n",
      "Epoch 338/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.9125 - val_loss: 0.2059 - val_accuracy: 0.9500\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9156 - val_loss: 0.2207 - val_accuracy: 0.9375\n",
      "Epoch 340/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.9156 - val_loss: 0.2273 - val_accuracy: 0.9250\n",
      "Epoch 341/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2939 - accuracy: 0.9156 - val_loss: 0.2254 - val_accuracy: 0.9250\n",
      "Epoch 342/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.9125 - val_loss: 0.2062 - val_accuracy: 0.9375\n",
      "Epoch 343/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.9125 - val_loss: 0.2290 - val_accuracy: 0.9250\n",
      "Epoch 344/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9156 - val_loss: 0.2160 - val_accuracy: 0.9375\n",
      "Epoch 345/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.9125 - val_loss: 0.2259 - val_accuracy: 0.9250\n",
      "Epoch 346/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9156 - val_loss: 0.2250 - val_accuracy: 0.9250\n",
      "Epoch 347/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2971 - accuracy: 0.9156 - val_loss: 0.2108 - val_accuracy: 0.9500\n",
      "Epoch 348/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.9156 - val_loss: 0.2002 - val_accuracy: 0.9500\n",
      "Epoch 349/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2825 - accuracy: 0.9125 - val_loss: 0.2162 - val_accuracy: 0.9375\n",
      "Epoch 350/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.9125 - val_loss: 0.2379 - val_accuracy: 0.9250\n",
      "Epoch 351/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2958 - accuracy: 0.9156 - val_loss: 0.1875 - val_accuracy: 0.9500\n",
      "Epoch 352/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2899 - accuracy: 0.9156 - val_loss: 0.2136 - val_accuracy: 0.9375\n",
      "Epoch 353/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.9156 - val_loss: 0.2378 - val_accuracy: 0.9000\n",
      "Epoch 354/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9156 - val_loss: 0.2267 - val_accuracy: 0.9250\n",
      "Epoch 355/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.9156 - val_loss: 0.2025 - val_accuracy: 0.9500\n",
      "Epoch 356/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.9156 - val_loss: 0.2187 - val_accuracy: 0.9375\n",
      "Epoch 357/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.9156 - val_loss: 0.2458 - val_accuracy: 0.9125\n",
      "Epoch 358/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.9125 - val_loss: 0.1990 - val_accuracy: 0.9375\n",
      "Epoch 359/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.9125 - val_loss: 0.2170 - val_accuracy: 0.9375\n",
      "Epoch 360/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.9125 - val_loss: 0.2215 - val_accuracy: 0.9375\n",
      "Epoch 361/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.9156 - val_loss: 0.2067 - val_accuracy: 0.9500\n",
      "Epoch 362/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.9156 - val_loss: 0.2203 - val_accuracy: 0.9375\n",
      "Epoch 363/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9094 - val_loss: 0.2194 - val_accuracy: 0.9375\n",
      "Epoch 364/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.9156 - val_loss: 0.1970 - val_accuracy: 0.9375\n",
      "Epoch 365/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2768 - accuracy: 0.9125 - val_loss: 0.2148 - val_accuracy: 0.9375\n",
      "Epoch 366/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.9094 - val_loss: 0.2009 - val_accuracy: 0.9375\n",
      "Epoch 367/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.9125 - val_loss: 0.2292 - val_accuracy: 0.9250\n",
      "Epoch 368/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.9094 - val_loss: 0.2138 - val_accuracy: 0.9125\n",
      "Epoch 369/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2959 - accuracy: 0.9156 - val_loss: 0.2147 - val_accuracy: 0.9375\n",
      "Epoch 370/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.9125 - val_loss: 0.2295 - val_accuracy: 0.9375\n",
      "Epoch 371/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9062 - val_loss: 0.2071 - val_accuracy: 0.9500\n",
      "Epoch 372/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9094 - val_loss: 0.2186 - val_accuracy: 0.9375\n",
      "Epoch 373/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9125 - val_loss: 0.2287 - val_accuracy: 0.9250\n",
      "Epoch 374/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.9187 - val_loss: 0.2409 - val_accuracy: 0.9250\n",
      "Epoch 375/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2801 - accuracy: 0.9156 - val_loss: 0.2132 - val_accuracy: 0.9250\n",
      "Epoch 376/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9125 - val_loss: 0.2033 - val_accuracy: 0.9375\n",
      "Epoch 377/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9156 - val_loss: 0.2249 - val_accuracy: 0.9250\n",
      "Epoch 378/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2897 - accuracy: 0.9125 - val_loss: 0.2299 - val_accuracy: 0.9125\n",
      "Epoch 379/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9125 - val_loss: 0.2204 - val_accuracy: 0.9250\n",
      "Epoch 380/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2828 - accuracy: 0.9156 - val_loss: 0.2094 - val_accuracy: 0.9375\n",
      "Epoch 381/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.9156 - val_loss: 0.2148 - val_accuracy: 0.9250\n",
      "Epoch 382/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.9156 - val_loss: 0.2094 - val_accuracy: 0.9375\n",
      "Epoch 383/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.9156 - val_loss: 0.2139 - val_accuracy: 0.9375\n",
      "Epoch 384/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.9156 - val_loss: 0.2263 - val_accuracy: 0.9500\n",
      "Epoch 385/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9156 - val_loss: 0.2117 - val_accuracy: 0.9375\n",
      "Epoch 386/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.9187 - val_loss: 0.2032 - val_accuracy: 0.9375\n",
      "Epoch 387/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2876 - accuracy: 0.9125 - val_loss: 0.2068 - val_accuracy: 0.9375\n",
      "Epoch 388/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.9156 - val_loss: 0.2029 - val_accuracy: 0.9500\n",
      "Epoch 389/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.9094 - val_loss: 0.2061 - val_accuracy: 0.9500\n",
      "Epoch 390/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.9156 - val_loss: 0.1928 - val_accuracy: 0.9375\n",
      "Epoch 391/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.9156 - val_loss: 0.2022 - val_accuracy: 0.9500\n",
      "Epoch 392/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.9187 - val_loss: 0.2065 - val_accuracy: 0.9500\n",
      "Epoch 393/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.9125 - val_loss: 0.2019 - val_accuracy: 0.9500\n",
      "Epoch 394/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.9156 - val_loss: 0.2260 - val_accuracy: 0.9375\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9156 - val_loss: 0.2120 - val_accuracy: 0.9375\n",
      "Epoch 396/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9187 - val_loss: 0.2003 - val_accuracy: 0.9500\n",
      "Epoch 397/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.9156 - val_loss: 0.2001 - val_accuracy: 0.9500\n",
      "Epoch 398/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9187 - val_loss: 0.2279 - val_accuracy: 0.9375\n",
      "Epoch 399/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.9125 - val_loss: 0.1989 - val_accuracy: 0.9500\n",
      "Epoch 400/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2986 - accuracy: 0.9156 - val_loss: 0.2109 - val_accuracy: 0.9375\n",
      "Epoch 401/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.9156 - val_loss: 0.2338 - val_accuracy: 0.9375\n",
      "Epoch 402/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.9156 - val_loss: 0.2172 - val_accuracy: 0.9375\n",
      "Epoch 403/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2876 - accuracy: 0.9156 - val_loss: 0.2186 - val_accuracy: 0.9375\n",
      "Epoch 404/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.9156 - val_loss: 0.2280 - val_accuracy: 0.9375\n",
      "Epoch 405/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.9187 - val_loss: 0.2264 - val_accuracy: 0.9375\n",
      "Epoch 406/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.9156 - val_loss: 0.2146 - val_accuracy: 0.9375\n",
      "Epoch 407/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2921 - accuracy: 0.9156 - val_loss: 0.2032 - val_accuracy: 0.9375\n",
      "Epoch 408/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.9187 - val_loss: 0.2183 - val_accuracy: 0.9375\n",
      "Epoch 409/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2815 - accuracy: 0.9187 - val_loss: 0.2020 - val_accuracy: 0.9500\n",
      "Epoch 410/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.9187 - val_loss: 0.2090 - val_accuracy: 0.9500\n",
      "Epoch 411/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2984 - accuracy: 0.9156 - val_loss: 0.1892 - val_accuracy: 0.9500\n",
      "Epoch 412/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.9156 - val_loss: 0.2068 - val_accuracy: 0.9500\n",
      "Epoch 413/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.9156 - val_loss: 0.2284 - val_accuracy: 0.9250\n",
      "Epoch 414/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2964 - accuracy: 0.9094 - val_loss: 0.1780 - val_accuracy: 0.9500\n",
      "Epoch 415/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.9156 - val_loss: 0.2039 - val_accuracy: 0.9500\n",
      "Epoch 416/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9187 - val_loss: 0.1893 - val_accuracy: 0.9500\n",
      "Epoch 417/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9156 - val_loss: 0.1913 - val_accuracy: 0.9500\n",
      "Epoch 418/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.9187 - val_loss: 0.1882 - val_accuracy: 0.9500\n",
      "Epoch 419/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.9187 - val_loss: 0.1890 - val_accuracy: 0.9500\n",
      "Epoch 420/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.9156 - val_loss: 0.2026 - val_accuracy: 0.9500\n",
      "Epoch 421/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.9156 - val_loss: 0.2038 - val_accuracy: 0.9500\n",
      "Epoch 422/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9156 - val_loss: 0.2214 - val_accuracy: 0.9500\n",
      "Epoch 423/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.9094 - val_loss: 0.2196 - val_accuracy: 0.9375\n",
      "Epoch 424/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9187 - val_loss: 0.2192 - val_accuracy: 0.9500\n",
      "Epoch 425/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9187 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 426/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.9156 - val_loss: 0.1860 - val_accuracy: 0.9500\n",
      "Epoch 427/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.9156 - val_loss: 0.2027 - val_accuracy: 0.9500\n",
      "Epoch 428/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.9125 - val_loss: 0.1900 - val_accuracy: 0.9500\n",
      "Epoch 429/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.9094 - val_loss: 0.2234 - val_accuracy: 0.9375\n",
      "Epoch 430/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.9156 - val_loss: 0.2061 - val_accuracy: 0.9500\n",
      "Epoch 431/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.9187 - val_loss: 0.1998 - val_accuracy: 0.9500\n",
      "Epoch 432/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.9156 - val_loss: 0.2074 - val_accuracy: 0.9500\n",
      "Epoch 433/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9156 - val_loss: 0.2073 - val_accuracy: 0.9500\n",
      "Epoch 434/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.9156 - val_loss: 0.2094 - val_accuracy: 0.9500\n",
      "Epoch 435/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2959 - accuracy: 0.9125 - val_loss: 0.2090 - val_accuracy: 0.9500\n",
      "Epoch 436/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.9187 - val_loss: 0.2283 - val_accuracy: 0.9375\n",
      "Epoch 437/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.9125 - val_loss: 0.1966 - val_accuracy: 0.9500\n",
      "Epoch 438/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.9187 - val_loss: 0.2040 - val_accuracy: 0.9500\n",
      "Epoch 439/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2917 - accuracy: 0.9125 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
      "Epoch 440/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2924 - accuracy: 0.9187 - val_loss: 0.2257 - val_accuracy: 0.9375\n",
      "Epoch 441/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.9156 - val_loss: 0.2043 - val_accuracy: 0.9500\n",
      "Epoch 442/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.9156 - val_loss: 0.2056 - val_accuracy: 0.9500\n",
      "Epoch 443/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9187 - val_loss: 0.2111 - val_accuracy: 0.9500\n",
      "Epoch 444/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.9156 - val_loss: 0.1997 - val_accuracy: 0.9500\n",
      "Epoch 445/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.9156 - val_loss: 0.2034 - val_accuracy: 0.9500\n",
      "Epoch 446/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.9156 - val_loss: 0.2215 - val_accuracy: 0.9500\n",
      "Epoch 447/500\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.9156 - val_loss: 0.2061 - val_accuracy: 0.9500\n",
      "Epoch 448/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2966 - accuracy: 0.9156 - val_loss: 0.2124 - val_accuracy: 0.9500\n",
      "Epoch 449/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.9156 - val_loss: 0.2180 - val_accuracy: 0.9500\n",
      "Epoch 450/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.9156 - val_loss: 0.1946 - val_accuracy: 0.9500\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2991 - accuracy: 0.9187 - val_loss: 0.1937 - val_accuracy: 0.9500\n",
      "Epoch 452/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.9156 - val_loss: 0.2042 - val_accuracy: 0.9500\n",
      "Epoch 453/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3066 - accuracy: 0.9156 - val_loss: 0.1927 - val_accuracy: 0.9500\n",
      "Epoch 454/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.9156 - val_loss: 0.2060 - val_accuracy: 0.9500\n",
      "Epoch 455/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.9125 - val_loss: 0.2162 - val_accuracy: 0.9375\n",
      "Epoch 456/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.9156 - val_loss: 0.2254 - val_accuracy: 0.9375\n",
      "Epoch 457/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9156 - val_loss: 0.2166 - val_accuracy: 0.9500\n",
      "Epoch 458/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.9125 - val_loss: 0.2292 - val_accuracy: 0.9500\n",
      "Epoch 459/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.9125 - val_loss: 0.2108 - val_accuracy: 0.9500\n",
      "Epoch 460/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9125 - val_loss: 0.1926 - val_accuracy: 0.9500\n",
      "Epoch 461/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3105 - accuracy: 0.9094 - val_loss: 0.2042 - val_accuracy: 0.9500\n",
      "Epoch 462/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.9125 - val_loss: 0.1984 - val_accuracy: 0.9500\n",
      "Epoch 463/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.9156 - val_loss: 0.2123 - val_accuracy: 0.9500\n",
      "Epoch 464/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.9125 - val_loss: 0.2292 - val_accuracy: 0.9375\n",
      "Epoch 465/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2805 - accuracy: 0.9094 - val_loss: 0.2202 - val_accuracy: 0.9500\n",
      "Epoch 466/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.9156 - val_loss: 0.1987 - val_accuracy: 0.9500\n",
      "Epoch 467/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.9125 - val_loss: 0.2008 - val_accuracy: 0.9500\n",
      "Epoch 468/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.9125 - val_loss: 0.1910 - val_accuracy: 0.9500\n",
      "Epoch 469/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9156 - val_loss: 0.1930 - val_accuracy: 0.9500\n",
      "Epoch 470/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.9125 - val_loss: 0.2048 - val_accuracy: 0.9500\n",
      "Epoch 471/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.9125 - val_loss: 0.1960 - val_accuracy: 0.9500\n",
      "Epoch 472/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.9125 - val_loss: 0.2172 - val_accuracy: 0.9500\n",
      "Epoch 473/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.9094 - val_loss: 0.2134 - val_accuracy: 0.9500\n",
      "Epoch 474/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.9125 - val_loss: 0.2126 - val_accuracy: 0.9500\n",
      "Epoch 475/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.9125 - val_loss: 0.2239 - val_accuracy: 0.9500\n",
      "Epoch 476/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.9062 - val_loss: 0.2086 - val_accuracy: 0.9500\n",
      "Epoch 477/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.9094 - val_loss: 0.2126 - val_accuracy: 0.9500\n",
      "Epoch 478/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.9125 - val_loss: 0.2079 - val_accuracy: 0.9500\n",
      "Epoch 479/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.9094 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
      "Epoch 480/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9125 - val_loss: 0.2065 - val_accuracy: 0.9500\n",
      "Epoch 481/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.9094 - val_loss: 0.2131 - val_accuracy: 0.9500\n",
      "Epoch 482/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.9125 - val_loss: 0.2241 - val_accuracy: 0.9375\n",
      "Epoch 483/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3037 - accuracy: 0.9094 - val_loss: 0.2032 - val_accuracy: 0.9500\n",
      "Epoch 484/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9125 - val_loss: 0.2187 - val_accuracy: 0.9500\n",
      "Epoch 485/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.9094 - val_loss: 0.2210 - val_accuracy: 0.9500\n",
      "Epoch 486/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2955 - accuracy: 0.9094 - val_loss: 0.2278 - val_accuracy: 0.9375\n",
      "Epoch 487/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.9062 - val_loss: 0.2227 - val_accuracy: 0.9375\n",
      "Epoch 488/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.9125 - val_loss: 0.1890 - val_accuracy: 0.9500\n",
      "Epoch 489/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.9125 - val_loss: 0.2044 - val_accuracy: 0.9500\n",
      "Epoch 490/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.9062 - val_loss: 0.2022 - val_accuracy: 0.9500\n",
      "Epoch 491/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.9062 - val_loss: 0.2041 - val_accuracy: 0.9500\n",
      "Epoch 492/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2774 - accuracy: 0.9094 - val_loss: 0.2010 - val_accuracy: 0.9500\n",
      "Epoch 493/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9094 - val_loss: 0.2080 - val_accuracy: 0.9500\n",
      "Epoch 494/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2915 - accuracy: 0.9156 - val_loss: 0.1935 - val_accuracy: 0.9500\n",
      "Epoch 495/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3037 - accuracy: 0.9156 - val_loss: 0.2038 - val_accuracy: 0.9500\n",
      "Epoch 496/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.9156 - val_loss: 0.2187 - val_accuracy: 0.9375\n",
      "Epoch 497/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.9094 - val_loss: 0.2031 - val_accuracy: 0.9500\n",
      "Epoch 498/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.9125 - val_loss: 0.1998 - val_accuracy: 0.9500\n",
      "Epoch 499/500\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9094 - val_loss: 0.2174 - val_accuracy: 0.9500\n",
      "Epoch 500/500\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.9094 - val_loss: 0.2141 - val_accuracy: 0.9375\n",
      "Run_Time: 408.93993616104126\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics='accuracy')\n",
    "start = time.time()\n",
    "\"\"\"Here i am skiping Train_test_spiliting i will take X_scaled it's mean 400 rows and y\"\"\"\n",
    "histroy = model.fit(X_scaled, y, epochs=500, batch_size=1, validation_split=0.2)\n",
    "print(f'Run_Time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5406f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_accuracy: 0.9375\n",
    "# Run_Time: 408.93993616104126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4ccb2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f7fb35900>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histroy.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b299ce42",
   "metadata": {},
   "source": [
    "# Batch_Size GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8acb0e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2966 - accuracy: 0.9094 - val_loss: 0.2184 - val_accuracy: 0.9375\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2822 - accuracy: 0.9062 - val_loss: 0.2225 - val_accuracy: 0.9375\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2727 - accuracy: 0.9062 - val_loss: 0.2256 - val_accuracy: 0.9375\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2657 - accuracy: 0.9094 - val_loss: 0.2297 - val_accuracy: 0.9375\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2608 - accuracy: 0.9125 - val_loss: 0.2314 - val_accuracy: 0.9250\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2570 - accuracy: 0.9125 - val_loss: 0.2352 - val_accuracy: 0.9250\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2538 - accuracy: 0.9125 - val_loss: 0.2374 - val_accuracy: 0.9250\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2512 - accuracy: 0.9125 - val_loss: 0.2398 - val_accuracy: 0.9250\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2490 - accuracy: 0.9125 - val_loss: 0.2418 - val_accuracy: 0.9250\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2470 - accuracy: 0.9125 - val_loss: 0.2451 - val_accuracy: 0.9250\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2454 - accuracy: 0.9094 - val_loss: 0.2458 - val_accuracy: 0.9125\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2440 - accuracy: 0.9094 - val_loss: 0.2489 - val_accuracy: 0.9125\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2426 - accuracy: 0.9094 - val_loss: 0.2497 - val_accuracy: 0.9125\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2414 - accuracy: 0.9094 - val_loss: 0.2530 - val_accuracy: 0.9125\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2401 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9125\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2391 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9125\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2380 - accuracy: 0.9094 - val_loss: 0.2569 - val_accuracy: 0.9125\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2371 - accuracy: 0.9094 - val_loss: 0.2587 - val_accuracy: 0.9125\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2362 - accuracy: 0.9094 - val_loss: 0.2592 - val_accuracy: 0.9125\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2355 - accuracy: 0.9094 - val_loss: 0.2615 - val_accuracy: 0.9125\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2348 - accuracy: 0.9094 - val_loss: 0.2612 - val_accuracy: 0.9125\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2341 - accuracy: 0.9094 - val_loss: 0.2634 - val_accuracy: 0.9125\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2335 - accuracy: 0.9094 - val_loss: 0.2643 - val_accuracy: 0.9125\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2329 - accuracy: 0.9094 - val_loss: 0.2658 - val_accuracy: 0.9125\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2323 - accuracy: 0.9062 - val_loss: 0.2659 - val_accuracy: 0.9125\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2318 - accuracy: 0.9094 - val_loss: 0.2675 - val_accuracy: 0.9125\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2314 - accuracy: 0.9062 - val_loss: 0.2670 - val_accuracy: 0.9125\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2311 - accuracy: 0.9062 - val_loss: 0.2687 - val_accuracy: 0.9125\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2308 - accuracy: 0.9062 - val_loss: 0.2682 - val_accuracy: 0.9125\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2305 - accuracy: 0.9062 - val_loss: 0.2712 - val_accuracy: 0.9125\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2302 - accuracy: 0.9094 - val_loss: 0.2699 - val_accuracy: 0.9125\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2300 - accuracy: 0.9062 - val_loss: 0.2707 - val_accuracy: 0.9125\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2297 - accuracy: 0.9062 - val_loss: 0.2698 - val_accuracy: 0.9125\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2294 - accuracy: 0.9062 - val_loss: 0.2707 - val_accuracy: 0.9125\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2292 - accuracy: 0.9062 - val_loss: 0.2702 - val_accuracy: 0.9125\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2289 - accuracy: 0.9062 - val_loss: 0.2700 - val_accuracy: 0.9125\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2288 - accuracy: 0.9094 - val_loss: 0.2704 - val_accuracy: 0.9125\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2285 - accuracy: 0.9062 - val_loss: 0.2703 - val_accuracy: 0.9125\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2283 - accuracy: 0.9094 - val_loss: 0.2691 - val_accuracy: 0.9125\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2281 - accuracy: 0.9094 - val_loss: 0.2700 - val_accuracy: 0.9125\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2278 - accuracy: 0.9094 - val_loss: 0.2692 - val_accuracy: 0.9125\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2276 - accuracy: 0.9094 - val_loss: 0.2691 - val_accuracy: 0.9125\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2273 - accuracy: 0.9094 - val_loss: 0.2686 - val_accuracy: 0.9125\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2271 - accuracy: 0.9094 - val_loss: 0.2680 - val_accuracy: 0.9125\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2269 - accuracy: 0.9094 - val_loss: 0.2684 - val_accuracy: 0.9125\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2266 - accuracy: 0.9125 - val_loss: 0.2682 - val_accuracy: 0.9125\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2264 - accuracy: 0.9125 - val_loss: 0.2670 - val_accuracy: 0.9125\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2262 - accuracy: 0.9125 - val_loss: 0.2682 - val_accuracy: 0.9125\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2259 - accuracy: 0.9125 - val_loss: 0.2667 - val_accuracy: 0.9125\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2257 - accuracy: 0.9125 - val_loss: 0.2671 - val_accuracy: 0.9125\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2255 - accuracy: 0.9125 - val_loss: 0.2663 - val_accuracy: 0.9125\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2251 - accuracy: 0.9125 - val_loss: 0.2682 - val_accuracy: 0.9125\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2248 - accuracy: 0.9156 - val_loss: 0.2659 - val_accuracy: 0.9125\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2245 - accuracy: 0.9125 - val_loss: 0.2678 - val_accuracy: 0.9125\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2241 - accuracy: 0.9156 - val_loss: 0.2661 - val_accuracy: 0.9125\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2238 - accuracy: 0.9094 - val_loss: 0.2669 - val_accuracy: 0.9125\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2235 - accuracy: 0.9094 - val_loss: 0.2654 - val_accuracy: 0.9375\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2232 - accuracy: 0.9125 - val_loss: 0.2664 - val_accuracy: 0.9125\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2228 - accuracy: 0.9125 - val_loss: 0.2659 - val_accuracy: 0.9125\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2226 - accuracy: 0.9125 - val_loss: 0.2673 - val_accuracy: 0.9125\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2223 - accuracy: 0.9156 - val_loss: 0.2641 - val_accuracy: 0.9375\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2221 - accuracy: 0.9125 - val_loss: 0.2676 - val_accuracy: 0.9125\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2216 - accuracy: 0.9156 - val_loss: 0.2648 - val_accuracy: 0.9250\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2213 - accuracy: 0.9187 - val_loss: 0.2655 - val_accuracy: 0.9250\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2210 - accuracy: 0.9187 - val_loss: 0.2652 - val_accuracy: 0.9375\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2207 - accuracy: 0.9187 - val_loss: 0.2645 - val_accuracy: 0.9375\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2204 - accuracy: 0.9187 - val_loss: 0.2657 - val_accuracy: 0.9250\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2201 - accuracy: 0.9187 - val_loss: 0.2628 - val_accuracy: 0.9375\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2199 - accuracy: 0.9156 - val_loss: 0.2664 - val_accuracy: 0.9125\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2197 - accuracy: 0.9187 - val_loss: 0.2608 - val_accuracy: 0.9375\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2195 - accuracy: 0.9156 - val_loss: 0.2660 - val_accuracy: 0.9250\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2192 - accuracy: 0.9187 - val_loss: 0.2628 - val_accuracy: 0.9375\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2190 - accuracy: 0.9187 - val_loss: 0.2628 - val_accuracy: 0.9375\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2188 - accuracy: 0.9187 - val_loss: 0.2630 - val_accuracy: 0.9375\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2186 - accuracy: 0.9187 - val_loss: 0.2630 - val_accuracy: 0.9375\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2185 - accuracy: 0.9187 - val_loss: 0.2633 - val_accuracy: 0.9375\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2183 - accuracy: 0.9187 - val_loss: 0.2633 - val_accuracy: 0.9375\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2182 - accuracy: 0.9187 - val_loss: 0.2606 - val_accuracy: 0.9375\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2180 - accuracy: 0.9156 - val_loss: 0.2638 - val_accuracy: 0.9375\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2178 - accuracy: 0.9187 - val_loss: 0.2600 - val_accuracy: 0.9500\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2176 - accuracy: 0.9156 - val_loss: 0.2627 - val_accuracy: 0.9375\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2174 - accuracy: 0.9187 - val_loss: 0.2599 - val_accuracy: 0.9500\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2173 - accuracy: 0.9156 - val_loss: 0.2627 - val_accuracy: 0.9375\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2170 - accuracy: 0.9187 - val_loss: 0.2587 - val_accuracy: 0.9500\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2170 - accuracy: 0.9156 - val_loss: 0.2626 - val_accuracy: 0.9375\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2167 - accuracy: 0.9187 - val_loss: 0.2618 - val_accuracy: 0.9375\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2165 - accuracy: 0.9187 - val_loss: 0.2604 - val_accuracy: 0.9500\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2163 - accuracy: 0.9187 - val_loss: 0.2613 - val_accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2161 - accuracy: 0.9187 - val_loss: 0.2590 - val_accuracy: 0.9500\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2159 - accuracy: 0.9156 - val_loss: 0.2623 - val_accuracy: 0.9375\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2157 - accuracy: 0.9187 - val_loss: 0.2560 - val_accuracy: 0.9500\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2156 - accuracy: 0.9156 - val_loss: 0.2624 - val_accuracy: 0.9500\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2154 - accuracy: 0.9187 - val_loss: 0.2580 - val_accuracy: 0.9500\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2152 - accuracy: 0.9156 - val_loss: 0.2600 - val_accuracy: 0.9500\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2151 - accuracy: 0.9187 - val_loss: 0.2582 - val_accuracy: 0.9500\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2149 - accuracy: 0.9156 - val_loss: 0.2605 - val_accuracy: 0.9500\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2148 - accuracy: 0.9187 - val_loss: 0.2567 - val_accuracy: 0.9500\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2147 - accuracy: 0.9156 - val_loss: 0.2606 - val_accuracy: 0.9500\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2146 - accuracy: 0.9187 - val_loss: 0.2588 - val_accuracy: 0.9500\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2143 - accuracy: 0.9156 - val_loss: 0.2583 - val_accuracy: 0.9500\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2141 - accuracy: 0.9156 - val_loss: 0.2577 - val_accuracy: 0.9500\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2139 - accuracy: 0.9156 - val_loss: 0.2574 - val_accuracy: 0.9500\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2137 - accuracy: 0.9156 - val_loss: 0.2583 - val_accuracy: 0.9500\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2136 - accuracy: 0.9156 - val_loss: 0.2568 - val_accuracy: 0.9500\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2134 - accuracy: 0.9156 - val_loss: 0.2595 - val_accuracy: 0.9500\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2134 - accuracy: 0.9187 - val_loss: 0.2550 - val_accuracy: 0.9500\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2131 - accuracy: 0.9156 - val_loss: 0.2595 - val_accuracy: 0.9500\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2130 - accuracy: 0.9187 - val_loss: 0.2533 - val_accuracy: 0.9500\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2130 - accuracy: 0.9156 - val_loss: 0.2600 - val_accuracy: 0.9500\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2128 - accuracy: 0.9187 - val_loss: 0.2537 - val_accuracy: 0.9500\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2127 - accuracy: 0.9156 - val_loss: 0.2592 - val_accuracy: 0.9500\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2125 - accuracy: 0.9187 - val_loss: 0.2539 - val_accuracy: 0.9500\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2124 - accuracy: 0.9156 - val_loss: 0.2578 - val_accuracy: 0.9500\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2122 - accuracy: 0.9187 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2122 - accuracy: 0.9156 - val_loss: 0.2570 - val_accuracy: 0.9500\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2120 - accuracy: 0.9187 - val_loss: 0.2523 - val_accuracy: 0.9500\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2119 - accuracy: 0.9156 - val_loss: 0.2560 - val_accuracy: 0.9500\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2117 - accuracy: 0.9187 - val_loss: 0.2506 - val_accuracy: 0.9500\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2117 - accuracy: 0.9156 - val_loss: 0.2554 - val_accuracy: 0.9500\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2115 - accuracy: 0.9156 - val_loss: 0.2515 - val_accuracy: 0.9500\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2114 - accuracy: 0.9156 - val_loss: 0.2549 - val_accuracy: 0.9500\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2113 - accuracy: 0.9187 - val_loss: 0.2502 - val_accuracy: 0.9500\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2112 - accuracy: 0.9156 - val_loss: 0.2544 - val_accuracy: 0.9500\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2110 - accuracy: 0.9156 - val_loss: 0.2501 - val_accuracy: 0.9500\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2109 - accuracy: 0.9156 - val_loss: 0.2548 - val_accuracy: 0.9500\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2109 - accuracy: 0.9187 - val_loss: 0.2498 - val_accuracy: 0.9500\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2109 - accuracy: 0.9156 - val_loss: 0.2558 - val_accuracy: 0.9500\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2108 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9500\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2106 - accuracy: 0.9156 - val_loss: 0.2549 - val_accuracy: 0.9500\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2104 - accuracy: 0.9187 - val_loss: 0.2495 - val_accuracy: 0.9500\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2105 - accuracy: 0.9156 - val_loss: 0.2537 - val_accuracy: 0.9500\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2102 - accuracy: 0.9187 - val_loss: 0.2500 - val_accuracy: 0.9500\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2102 - accuracy: 0.9156 - val_loss: 0.2533 - val_accuracy: 0.9500\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2101 - accuracy: 0.9187 - val_loss: 0.2522 - val_accuracy: 0.9500\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2100 - accuracy: 0.9187 - val_loss: 0.2561 - val_accuracy: 0.9500\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2098 - accuracy: 0.9187 - val_loss: 0.2514 - val_accuracy: 0.9500\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2098 - accuracy: 0.9187 - val_loss: 0.2561 - val_accuracy: 0.9500\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2097 - accuracy: 0.9187 - val_loss: 0.2543 - val_accuracy: 0.9500\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2094 - accuracy: 0.9187 - val_loss: 0.2545 - val_accuracy: 0.9500\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2094 - accuracy: 0.9187 - val_loss: 0.2559 - val_accuracy: 0.9500\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2093 - accuracy: 0.9187 - val_loss: 0.2529 - val_accuracy: 0.9500\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2093 - accuracy: 0.9187 - val_loss: 0.2553 - val_accuracy: 0.9500\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2091 - accuracy: 0.9187 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2091 - accuracy: 0.9187 - val_loss: 0.2551 - val_accuracy: 0.9500\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2090 - accuracy: 0.9187 - val_loss: 0.2527 - val_accuracy: 0.9500\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2089 - accuracy: 0.9187 - val_loss: 0.2544 - val_accuracy: 0.9500\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2088 - accuracy: 0.9187 - val_loss: 0.2527 - val_accuracy: 0.9500\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2089 - accuracy: 0.9187 - val_loss: 0.2538 - val_accuracy: 0.9500\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2087 - accuracy: 0.9187 - val_loss: 0.2516 - val_accuracy: 0.9500\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2086 - accuracy: 0.9187 - val_loss: 0.2538 - val_accuracy: 0.9500\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2085 - accuracy: 0.9187 - val_loss: 0.2523 - val_accuracy: 0.9500\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2085 - accuracy: 0.9187 - val_loss: 0.2509 - val_accuracy: 0.9500\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2085 - accuracy: 0.9187 - val_loss: 0.2554 - val_accuracy: 0.9500\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2084 - accuracy: 0.9187 - val_loss: 0.2477 - val_accuracy: 0.9500\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2086 - accuracy: 0.9187 - val_loss: 0.2581 - val_accuracy: 0.9500\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2084 - accuracy: 0.9187 - val_loss: 0.2484 - val_accuracy: 0.9500\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2083 - accuracy: 0.9187 - val_loss: 0.2551 - val_accuracy: 0.9500\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2081 - accuracy: 0.9187 - val_loss: 0.2497 - val_accuracy: 0.9500\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2081 - accuracy: 0.9187 - val_loss: 0.2546 - val_accuracy: 0.9500\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2080 - accuracy: 0.9187 - val_loss: 0.2493 - val_accuracy: 0.9500\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2079 - accuracy: 0.9187 - val_loss: 0.2533 - val_accuracy: 0.9500\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2079 - accuracy: 0.9187 - val_loss: 0.2491 - val_accuracy: 0.9500\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2079 - accuracy: 0.9187 - val_loss: 0.2540 - val_accuracy: 0.9500\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2078 - accuracy: 0.9187 - val_loss: 0.2494 - val_accuracy: 0.9500\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2078 - accuracy: 0.9187 - val_loss: 0.2551 - val_accuracy: 0.9500\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2076 - accuracy: 0.9187 - val_loss: 0.2486 - val_accuracy: 0.9500\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2076 - accuracy: 0.9187 - val_loss: 0.2533 - val_accuracy: 0.9500\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2075 - accuracy: 0.9187 - val_loss: 0.2497 - val_accuracy: 0.9500\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2073 - accuracy: 0.9187 - val_loss: 0.2521 - val_accuracy: 0.9500\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2073 - accuracy: 0.9187 - val_loss: 0.2486 - val_accuracy: 0.9500\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2073 - accuracy: 0.9187 - val_loss: 0.2536 - val_accuracy: 0.9500\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2072 - accuracy: 0.9187 - val_loss: 0.2496 - val_accuracy: 0.9500\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2070 - accuracy: 0.9187 - val_loss: 0.2532 - val_accuracy: 0.9500\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2070 - accuracy: 0.9187 - val_loss: 0.2492 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2069 - accuracy: 0.9187 - val_loss: 0.2526 - val_accuracy: 0.9500\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2069 - accuracy: 0.9187 - val_loss: 0.2466 - val_accuracy: 0.9500\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2071 - accuracy: 0.9187 - val_loss: 0.2562 - val_accuracy: 0.9375\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2068 - accuracy: 0.9187 - val_loss: 0.2460 - val_accuracy: 0.9500\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2068 - accuracy: 0.9187 - val_loss: 0.2540 - val_accuracy: 0.9500\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2067 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9500\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2066 - accuracy: 0.9187 - val_loss: 0.2522 - val_accuracy: 0.9500\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2065 - accuracy: 0.9187 - val_loss: 0.2475 - val_accuracy: 0.9500\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2065 - accuracy: 0.9187 - val_loss: 0.2524 - val_accuracy: 0.9500\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2066 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9500\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2066 - accuracy: 0.9187 - val_loss: 0.2537 - val_accuracy: 0.9500\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2065 - accuracy: 0.9187 - val_loss: 0.2464 - val_accuracy: 0.9500\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2063 - accuracy: 0.9187 - val_loss: 0.2531 - val_accuracy: 0.9500\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2063 - accuracy: 0.9187 - val_loss: 0.2474 - val_accuracy: 0.9500\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2062 - accuracy: 0.9187 - val_loss: 0.2513 - val_accuracy: 0.9500\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2062 - accuracy: 0.9187 - val_loss: 0.2471 - val_accuracy: 0.9500\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2062 - accuracy: 0.9187 - val_loss: 0.2518 - val_accuracy: 0.9500\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2062 - accuracy: 0.9187 - val_loss: 0.2467 - val_accuracy: 0.9500\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2062 - accuracy: 0.9187 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2061 - accuracy: 0.9187 - val_loss: 0.2460 - val_accuracy: 0.9500\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2060 - accuracy: 0.9187 - val_loss: 0.2512 - val_accuracy: 0.9500\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2060 - accuracy: 0.9187 - val_loss: 0.2451 - val_accuracy: 0.9500\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2059 - accuracy: 0.9187 - val_loss: 0.2509 - val_accuracy: 0.9500\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2059 - accuracy: 0.9187 - val_loss: 0.2463 - val_accuracy: 0.9500\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2060 - accuracy: 0.9187 - val_loss: 0.2519 - val_accuracy: 0.9500\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2059 - accuracy: 0.9187 - val_loss: 0.2446 - val_accuracy: 0.9500\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2058 - accuracy: 0.9187 - val_loss: 0.2508 - val_accuracy: 0.9500\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2057 - accuracy: 0.9187 - val_loss: 0.2455 - val_accuracy: 0.9500\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2057 - accuracy: 0.9187 - val_loss: 0.2507 - val_accuracy: 0.9500\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2058 - accuracy: 0.9187 - val_loss: 0.2451 - val_accuracy: 0.9500\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2058 - accuracy: 0.9187 - val_loss: 0.2514 - val_accuracy: 0.9500\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2057 - accuracy: 0.9187 - val_loss: 0.2445 - val_accuracy: 0.9500\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2056 - accuracy: 0.9187 - val_loss: 0.2505 - val_accuracy: 0.9500\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2055 - accuracy: 0.9187 - val_loss: 0.2450 - val_accuracy: 0.9500\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2055 - accuracy: 0.9187 - val_loss: 0.2503 - val_accuracy: 0.9500\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2055 - accuracy: 0.9187 - val_loss: 0.2449 - val_accuracy: 0.9500\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2056 - accuracy: 0.9187 - val_loss: 0.2507 - val_accuracy: 0.9500\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2055 - accuracy: 0.9187 - val_loss: 0.2453 - val_accuracy: 0.9500\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2054 - accuracy: 0.9187 - val_loss: 0.2498 - val_accuracy: 0.9500\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2053 - accuracy: 0.9187 - val_loss: 0.2450 - val_accuracy: 0.9500\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2052 - accuracy: 0.9187 - val_loss: 0.2481 - val_accuracy: 0.9500\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2053 - accuracy: 0.9187 - val_loss: 0.2464 - val_accuracy: 0.9500\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2054 - accuracy: 0.9187 - val_loss: 0.2500 - val_accuracy: 0.9500\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2052 - accuracy: 0.9187 - val_loss: 0.2452 - val_accuracy: 0.9500\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2052 - accuracy: 0.9187 - val_loss: 0.2493 - val_accuracy: 0.9500\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2051 - accuracy: 0.9187 - val_loss: 0.2450 - val_accuracy: 0.9500\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2051 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9500\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2051 - accuracy: 0.9187 - val_loss: 0.2455 - val_accuracy: 0.9500\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2052 - accuracy: 0.9187 - val_loss: 0.2478 - val_accuracy: 0.9500\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2050 - accuracy: 0.9187 - val_loss: 0.2459 - val_accuracy: 0.9500\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2050 - accuracy: 0.9187 - val_loss: 0.2468 - val_accuracy: 0.9500\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2049 - accuracy: 0.9187 - val_loss: 0.2457 - val_accuracy: 0.9500\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2051 - accuracy: 0.9187 - val_loss: 0.2520 - val_accuracy: 0.9375\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2051 - accuracy: 0.9187 - val_loss: 0.2405 - val_accuracy: 0.9500\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2050 - accuracy: 0.9187 - val_loss: 0.2503 - val_accuracy: 0.9375\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2049 - accuracy: 0.9187 - val_loss: 0.2429 - val_accuracy: 0.9500\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2047 - accuracy: 0.9187 - val_loss: 0.2481 - val_accuracy: 0.9500\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2048 - accuracy: 0.9187 - val_loss: 0.2448 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2047 - accuracy: 0.9187 - val_loss: 0.2477 - val_accuracy: 0.9500\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2048 - accuracy: 0.9187 - val_loss: 0.2449 - val_accuracy: 0.9500\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2045 - accuracy: 0.9187 - val_loss: 0.2461 - val_accuracy: 0.9500\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2045 - accuracy: 0.9187 - val_loss: 0.2452 - val_accuracy: 0.9500\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2044 - accuracy: 0.9187 - val_loss: 0.2469 - val_accuracy: 0.9375\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2045 - accuracy: 0.9187 - val_loss: 0.2463 - val_accuracy: 0.9375\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2044 - accuracy: 0.9187 - val_loss: 0.2438 - val_accuracy: 0.9500\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2042 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9375\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2042 - accuracy: 0.9187 - val_loss: 0.2406 - val_accuracy: 0.9500\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2042 - accuracy: 0.9187 - val_loss: 0.2488 - val_accuracy: 0.9375\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2041 - accuracy: 0.9187 - val_loss: 0.2420 - val_accuracy: 0.9500\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2041 - accuracy: 0.9187 - val_loss: 0.2460 - val_accuracy: 0.9375\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2041 - accuracy: 0.9187 - val_loss: 0.2456 - val_accuracy: 0.9375\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2039 - accuracy: 0.9187 - val_loss: 0.2440 - val_accuracy: 0.9500\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2040 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9375\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2039 - accuracy: 0.9187 - val_loss: 0.2410 - val_accuracy: 0.9500\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2037 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9375\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2037 - accuracy: 0.9187 - val_loss: 0.2417 - val_accuracy: 0.9500\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2038 - accuracy: 0.9187 - val_loss: 0.2502 - val_accuracy: 0.9375\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2039 - accuracy: 0.9187 - val_loss: 0.2400 - val_accuracy: 0.9500\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2040 - accuracy: 0.9187 - val_loss: 0.2496 - val_accuracy: 0.9375\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2038 - accuracy: 0.9187 - val_loss: 0.2414 - val_accuracy: 0.9500\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2037 - accuracy: 0.9187 - val_loss: 0.2475 - val_accuracy: 0.9375\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2036 - accuracy: 0.9187 - val_loss: 0.2430 - val_accuracy: 0.9375\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2034 - accuracy: 0.9187 - val_loss: 0.2475 - val_accuracy: 0.9375\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2034 - accuracy: 0.9187 - val_loss: 0.2419 - val_accuracy: 0.9500\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2034 - accuracy: 0.9187 - val_loss: 0.2472 - val_accuracy: 0.9375\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2034 - accuracy: 0.9187 - val_loss: 0.2423 - val_accuracy: 0.9375\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2034 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9375\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2034 - accuracy: 0.9187 - val_loss: 0.2420 - val_accuracy: 0.9500\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2033 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9375\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2033 - accuracy: 0.9187 - val_loss: 0.2435 - val_accuracy: 0.9375\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2032 - accuracy: 0.9187 - val_loss: 0.2483 - val_accuracy: 0.9375\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2032 - accuracy: 0.9187 - val_loss: 0.2423 - val_accuracy: 0.9375\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2032 - accuracy: 0.9187 - val_loss: 0.2479 - val_accuracy: 0.9375\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2031 - accuracy: 0.9187 - val_loss: 0.2432 - val_accuracy: 0.9375\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2031 - accuracy: 0.9187 - val_loss: 0.2482 - val_accuracy: 0.9375\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2030 - accuracy: 0.9187 - val_loss: 0.2421 - val_accuracy: 0.9375\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2031 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9375\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2030 - accuracy: 0.9187 - val_loss: 0.2403 - val_accuracy: 0.9375\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2031 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9375\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2030 - accuracy: 0.9187 - val_loss: 0.2417 - val_accuracy: 0.9375\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2029 - accuracy: 0.9187 - val_loss: 0.2471 - val_accuracy: 0.9375\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2029 - accuracy: 0.9187 - val_loss: 0.2429 - val_accuracy: 0.9375\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2028 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9375\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2029 - accuracy: 0.9219 - val_loss: 0.2406 - val_accuracy: 0.9375\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2029 - accuracy: 0.9187 - val_loss: 0.2476 - val_accuracy: 0.9375\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2028 - accuracy: 0.9219 - val_loss: 0.2408 - val_accuracy: 0.9375\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2027 - accuracy: 0.9187 - val_loss: 0.2469 - val_accuracy: 0.9375\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2026 - accuracy: 0.9219 - val_loss: 0.2424 - val_accuracy: 0.9375\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2026 - accuracy: 0.9187 - val_loss: 0.2463 - val_accuracy: 0.9375\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2025 - accuracy: 0.9219 - val_loss: 0.2439 - val_accuracy: 0.9375\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2025 - accuracy: 0.9187 - val_loss: 0.2463 - val_accuracy: 0.9375\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2024 - accuracy: 0.9219 - val_loss: 0.2432 - val_accuracy: 0.9375\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2024 - accuracy: 0.9187 - val_loss: 0.2460 - val_accuracy: 0.9375\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2024 - accuracy: 0.9219 - val_loss: 0.2424 - val_accuracy: 0.9375\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2025 - accuracy: 0.9187 - val_loss: 0.2485 - val_accuracy: 0.9375\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2025 - accuracy: 0.9219 - val_loss: 0.2396 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2025 - accuracy: 0.9187 - val_loss: 0.2477 - val_accuracy: 0.9375\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2024 - accuracy: 0.9219 - val_loss: 0.2409 - val_accuracy: 0.9375\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2023 - accuracy: 0.9187 - val_loss: 0.2468 - val_accuracy: 0.9375\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2023 - accuracy: 0.9219 - val_loss: 0.2409 - val_accuracy: 0.9375\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2023 - accuracy: 0.9187 - val_loss: 0.2466 - val_accuracy: 0.9375\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2022 - accuracy: 0.9219 - val_loss: 0.2420 - val_accuracy: 0.9375\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2022 - accuracy: 0.9187 - val_loss: 0.2470 - val_accuracy: 0.9375\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2022 - accuracy: 0.9219 - val_loss: 0.2400 - val_accuracy: 0.9375\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2022 - accuracy: 0.9187 - val_loss: 0.2467 - val_accuracy: 0.9375\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2021 - accuracy: 0.9219 - val_loss: 0.2413 - val_accuracy: 0.9375\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2021 - accuracy: 0.9187 - val_loss: 0.2466 - val_accuracy: 0.9375\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2021 - accuracy: 0.9219 - val_loss: 0.2410 - val_accuracy: 0.9375\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2022 - accuracy: 0.9187 - val_loss: 0.2472 - val_accuracy: 0.9250\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2021 - accuracy: 0.9219 - val_loss: 0.2403 - val_accuracy: 0.9375\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2021 - accuracy: 0.9187 - val_loss: 0.2462 - val_accuracy: 0.9375\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2020 - accuracy: 0.9219 - val_loss: 0.2414 - val_accuracy: 0.9375\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2020 - accuracy: 0.9219 - val_loss: 0.2460 - val_accuracy: 0.9375\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2020 - accuracy: 0.9219 - val_loss: 0.2408 - val_accuracy: 0.9375\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2019 - accuracy: 0.9187 - val_loss: 0.2461 - val_accuracy: 0.9250\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2019 - accuracy: 0.9219 - val_loss: 0.2410 - val_accuracy: 0.9375\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2018 - accuracy: 0.9219 - val_loss: 0.2453 - val_accuracy: 0.9375\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2018 - accuracy: 0.9219 - val_loss: 0.2415 - val_accuracy: 0.9375\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2018 - accuracy: 0.9219 - val_loss: 0.2468 - val_accuracy: 0.9250\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2019 - accuracy: 0.9219 - val_loss: 0.2402 - val_accuracy: 0.9375\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2018 - accuracy: 0.9219 - val_loss: 0.2464 - val_accuracy: 0.9250\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2018 - accuracy: 0.9219 - val_loss: 0.2399 - val_accuracy: 0.9375\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2456 - val_accuracy: 0.9250\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2409 - val_accuracy: 0.9375\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2460 - val_accuracy: 0.9250\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2400 - val_accuracy: 0.9375\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2451 - val_accuracy: 0.9250\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2403 - val_accuracy: 0.9375\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2016 - accuracy: 0.9219 - val_loss: 0.2450 - val_accuracy: 0.9375\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2015 - accuracy: 0.9219 - val_loss: 0.2409 - val_accuracy: 0.9375\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2016 - accuracy: 0.9219 - val_loss: 0.2454 - val_accuracy: 0.9250\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2015 - accuracy: 0.9219 - val_loss: 0.2402 - val_accuracy: 0.9375\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2016 - accuracy: 0.9219 - val_loss: 0.2462 - val_accuracy: 0.9250\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2016 - accuracy: 0.9219 - val_loss: 0.2392 - val_accuracy: 0.9375\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2016 - accuracy: 0.9219 - val_loss: 0.2464 - val_accuracy: 0.9250\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.2377 - val_accuracy: 0.9375\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2015 - accuracy: 0.9219 - val_loss: 0.2444 - val_accuracy: 0.9250\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.2401 - val_accuracy: 0.9375\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.2445 - val_accuracy: 0.9250\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2399 - val_accuracy: 0.9375\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.2452 - val_accuracy: 0.9250\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2392 - val_accuracy: 0.9375\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.2445 - val_accuracy: 0.9250\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2387 - val_accuracy: 0.9375\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.2450 - val_accuracy: 0.9250\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.2384 - val_accuracy: 0.9375\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2439 - val_accuracy: 0.9250\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2400 - val_accuracy: 0.9375\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.2434 - val_accuracy: 0.9250\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2011 - accuracy: 0.9219 - val_loss: 0.2405 - val_accuracy: 0.9375\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.2444 - val_accuracy: 0.9250\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.2390 - val_accuracy: 0.9375\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2453 - val_accuracy: 0.9250\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.2381 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.2451 - val_accuracy: 0.9250\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2011 - accuracy: 0.9219 - val_loss: 0.2387 - val_accuracy: 0.9375\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2012 - accuracy: 0.9219 - val_loss: 0.2452 - val_accuracy: 0.9250\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2011 - accuracy: 0.9219 - val_loss: 0.2394 - val_accuracy: 0.9375\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2011 - accuracy: 0.9219 - val_loss: 0.2456 - val_accuracy: 0.9250\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2011 - accuracy: 0.9219 - val_loss: 0.2386 - val_accuracy: 0.9375\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2011 - accuracy: 0.9219 - val_loss: 0.2446 - val_accuracy: 0.9250\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2010 - accuracy: 0.9219 - val_loss: 0.2408 - val_accuracy: 0.9375\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2010 - accuracy: 0.9219 - val_loss: 0.2435 - val_accuracy: 0.9250\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2008 - accuracy: 0.9219 - val_loss: 0.2413 - val_accuracy: 0.9250\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2008 - accuracy: 0.9219 - val_loss: 0.2446 - val_accuracy: 0.9250\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.2396 - val_accuracy: 0.9375\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2008 - accuracy: 0.9219 - val_loss: 0.2435 - val_accuracy: 0.9250\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.2427 - val_accuracy: 0.9250\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2010 - accuracy: 0.9219 - val_loss: 0.2389 - val_accuracy: 0.9375\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.2465 - val_accuracy: 0.9250\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2010 - accuracy: 0.9219 - val_loss: 0.2372 - val_accuracy: 0.9375\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2010 - accuracy: 0.9219 - val_loss: 0.2454 - val_accuracy: 0.9250\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.2381 - val_accuracy: 0.9375\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2008 - accuracy: 0.9219 - val_loss: 0.2442 - val_accuracy: 0.9250\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2399 - val_accuracy: 0.9250\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2008 - accuracy: 0.9219 - val_loss: 0.2449 - val_accuracy: 0.9250\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2391 - val_accuracy: 0.9250\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2444 - val_accuracy: 0.9250\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2008 - accuracy: 0.9219 - val_loss: 0.2385 - val_accuracy: 0.9250\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2451 - val_accuracy: 0.9250\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2391 - val_accuracy: 0.9250\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.2440 - val_accuracy: 0.9250\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.2400 - val_accuracy: 0.9250\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2432 - val_accuracy: 0.9250\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2005 - accuracy: 0.9219 - val_loss: 0.2412 - val_accuracy: 0.9250\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2442 - val_accuracy: 0.9250\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2005 - accuracy: 0.9219 - val_loss: 0.2411 - val_accuracy: 0.9250\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2417 - val_accuracy: 0.9250\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.2443 - val_accuracy: 0.9250\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2372 - val_accuracy: 0.9250\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.2465 - val_accuracy: 0.9250\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.2370 - val_accuracy: 0.9250\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2005 - accuracy: 0.9219 - val_loss: 0.2445 - val_accuracy: 0.9250\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2005 - accuracy: 0.9219 - val_loss: 0.2389 - val_accuracy: 0.9250\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2441 - val_accuracy: 0.9250\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.2385 - val_accuracy: 0.9250\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2443 - val_accuracy: 0.9250\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2388 - val_accuracy: 0.9250\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2441 - val_accuracy: 0.9250\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.2394 - val_accuracy: 0.9250\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2446 - val_accuracy: 0.9250\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2379 - val_accuracy: 0.9250\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.2433 - val_accuracy: 0.9250\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.2386 - val_accuracy: 0.9250\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.2434 - val_accuracy: 0.9250\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2403 - val_accuracy: 0.9250\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2413 - val_accuracy: 0.9250\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2415 - val_accuracy: 0.9250\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2406 - val_accuracy: 0.9250\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2429 - val_accuracy: 0.9250\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.2364 - val_accuracy: 0.9250\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.2458 - val_accuracy: 0.9125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2359 - val_accuracy: 0.9250\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2001 - accuracy: 0.9219 - val_loss: 0.2433 - val_accuracy: 0.9250\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2001 - accuracy: 0.9219 - val_loss: 0.2375 - val_accuracy: 0.9250\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2001 - accuracy: 0.9219 - val_loss: 0.2434 - val_accuracy: 0.9250\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2379 - val_accuracy: 0.9250\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2431 - val_accuracy: 0.9250\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.2383 - val_accuracy: 0.9250\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.2436 - val_accuracy: 0.9250\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.2379 - val_accuracy: 0.9250\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2438 - val_accuracy: 0.9125\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2369 - val_accuracy: 0.9250\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.2431 - val_accuracy: 0.9250\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2391 - val_accuracy: 0.9250\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2428 - val_accuracy: 0.9250\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.2377 - val_accuracy: 0.9250\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2423 - val_accuracy: 0.9250\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2394 - val_accuracy: 0.9250\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2411 - val_accuracy: 0.9250\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.2403 - val_accuracy: 0.9250\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2413 - val_accuracy: 0.9250\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2372 - val_accuracy: 0.9250\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2440 - val_accuracy: 0.9250\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2357 - val_accuracy: 0.9250\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2445 - val_accuracy: 0.9125\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1999 - accuracy: 0.9187 - val_loss: 0.2356 - val_accuracy: 0.9250\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.2423 - val_accuracy: 0.9250\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1995 - accuracy: 0.9219 - val_loss: 0.2381 - val_accuracy: 0.9250\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.2419 - val_accuracy: 0.9250\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.2371 - val_accuracy: 0.9250\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2432 - val_accuracy: 0.9125\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.2360 - val_accuracy: 0.9250\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: 0.2417 - val_accuracy: 0.9250\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1995 - accuracy: 0.9219 - val_loss: 0.2377 - val_accuracy: 0.9250\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1995 - accuracy: 0.9219 - val_loss: 0.2427 - val_accuracy: 0.9125\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1996 - accuracy: 0.9187 - val_loss: 0.2362 - val_accuracy: 0.9250\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: 0.2427 - val_accuracy: 0.9125\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1995 - accuracy: 0.9219 - val_loss: 0.2361 - val_accuracy: 0.9250\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: 0.2418 - val_accuracy: 0.9125\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1995 - accuracy: 0.9187 - val_loss: 0.2368 - val_accuracy: 0.9250\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: 0.2424 - val_accuracy: 0.9250\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1993 - accuracy: 0.9187 - val_loss: 0.2375 - val_accuracy: 0.9250\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1992 - accuracy: 0.9219 - val_loss: 0.2404 - val_accuracy: 0.9250\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 0.2379 - val_accuracy: 0.9250\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 0.2404 - val_accuracy: 0.9125\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1995 - accuracy: 0.9187 - val_loss: 0.2360 - val_accuracy: 0.9250\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 0.2425 - val_accuracy: 0.9125\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1993 - accuracy: 0.9187 - val_loss: 0.2350 - val_accuracy: 0.9250\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 0.2426 - val_accuracy: 0.9125\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1994 - accuracy: 0.9187 - val_loss: 0.2349 - val_accuracy: 0.9250\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1992 - accuracy: 0.9219 - val_loss: 0.2412 - val_accuracy: 0.9125\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.2373 - val_accuracy: 0.9250\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1991 - accuracy: 0.9219 - val_loss: 0.2412 - val_accuracy: 0.9250\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.2363 - val_accuracy: 0.9250\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1992 - accuracy: 0.9219 - val_loss: 0.2432 - val_accuracy: 0.9125\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1993 - accuracy: 0.9187 - val_loss: 0.2350 - val_accuracy: 0.9250\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1992 - accuracy: 0.9219 - val_loss: 0.2424 - val_accuracy: 0.9125\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1992 - accuracy: 0.9187 - val_loss: 0.2355 - val_accuracy: 0.9250\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1991 - accuracy: 0.9219 - val_loss: 0.2428 - val_accuracy: 0.9125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.2359 - val_accuracy: 0.9250\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1989 - accuracy: 0.9219 - val_loss: 0.2414 - val_accuracy: 0.9125\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1990 - accuracy: 0.9187 - val_loss: 0.2375 - val_accuracy: 0.9250\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1990 - accuracy: 0.9219 - val_loss: 0.2401 - val_accuracy: 0.9125\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.2362 - val_accuracy: 0.9250\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1989 - accuracy: 0.9219 - val_loss: 0.2415 - val_accuracy: 0.9125\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1990 - accuracy: 0.9187 - val_loss: 0.2359 - val_accuracy: 0.9250\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1988 - accuracy: 0.9219 - val_loss: 0.2421 - val_accuracy: 0.9125\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1988 - accuracy: 0.9187 - val_loss: 0.2370 - val_accuracy: 0.9250\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1990 - accuracy: 0.9187 - val_loss: 0.2428 - val_accuracy: 0.9125\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.2347 - val_accuracy: 0.9250\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1989 - accuracy: 0.9219 - val_loss: 0.2435 - val_accuracy: 0.9125\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1990 - accuracy: 0.9187 - val_loss: 0.2353 - val_accuracy: 0.9250\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1988 - accuracy: 0.9219 - val_loss: 0.2414 - val_accuracy: 0.9125\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1988 - accuracy: 0.9187 - val_loss: 0.2364 - val_accuracy: 0.9125\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1987 - accuracy: 0.9187 - val_loss: 0.2399 - val_accuracy: 0.9125\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1987 - accuracy: 0.9187 - val_loss: 0.2367 - val_accuracy: 0.9125\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1988 - accuracy: 0.9187 - val_loss: 0.2434 - val_accuracy: 0.9125\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1990 - accuracy: 0.9187 - val_loss: 0.2348 - val_accuracy: 0.9250\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1988 - accuracy: 0.9187 - val_loss: 0.2429 - val_accuracy: 0.9125\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1988 - accuracy: 0.9187 - val_loss: 0.2360 - val_accuracy: 0.9125\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2404 - val_accuracy: 0.9125\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2370 - val_accuracy: 0.9125\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2409 - val_accuracy: 0.9125\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1985 - accuracy: 0.9187 - val_loss: 0.2367 - val_accuracy: 0.9125\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1985 - accuracy: 0.9187 - val_loss: 0.2417 - val_accuracy: 0.9125\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2358 - val_accuracy: 0.9125\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2438 - val_accuracy: 0.9125\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1988 - accuracy: 0.9156 - val_loss: 0.2346 - val_accuracy: 0.9250\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1987 - accuracy: 0.9187 - val_loss: 0.2439 - val_accuracy: 0.9125\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1988 - accuracy: 0.9187 - val_loss: 0.2354 - val_accuracy: 0.9250\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2413 - val_accuracy: 0.9125\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1986 - accuracy: 0.9187 - val_loss: 0.2354 - val_accuracy: 0.9250\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1985 - accuracy: 0.9187 - val_loss: 0.2433 - val_accuracy: 0.9125\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1985 - accuracy: 0.9187 - val_loss: 0.2353 - val_accuracy: 0.9250\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1985 - accuracy: 0.9187 - val_loss: 0.2426 - val_accuracy: 0.9125\n",
      "Run_Time: 29.62485408782959\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics='accuracy')\n",
    "start = time.time()\n",
    "\"\"\"Here i am skiping Train_test_spiliting i will take X_scaled it's mean 400 rows and y\"\"\"\n",
    "histroy = model.fit(X_scaled, y, epochs=500, batch_size=400, validation_split=0.2)\n",
    "print(f'Run_Time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "147d2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_accuracy: 0.9125\n",
    "# Run_Time: 29.62485408782959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a0eca59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f7edae710>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABAxklEQVR4nO3deXxU9b3/8fcsmZnsCyEJCYGAbKJCFEhEcOk1FVtbq9UWqVcobbXWrV6oVdqfYK+3DS7XS0Uu3EuvS1stdpHWulAVgbpE0ACygyCQEMhGSCbrzGTm/P4IGZqyJBOSOZPwej4e83jIOWe++Zwjmvfjux2LYRiGAAAAIpjV7AIAAAA6Q2ABAAARj8ACAAAiHoEFAABEPAILAACIeAQWAAAQ8QgsAAAg4hFYAABAxLObXUBPCAQCOnz4sOLj42WxWMwuBwAAdIFhGKqvr1dmZqas1jP3ofSLwHL48GFlZ2ebXQYAAOiG0tJSDR48+IzXdCuwLFmyRE888YTKy8s1fvx4LV68WHl5eae89pVXXtEvfvEL7d27Vz6fTyNHjtTcuXN12223Ba8xDEMLFizQ8uXLVVtbqylTpmjp0qUaOXJkl+qJj4+X1HbDCQkJ3bklAAAQZm63W9nZ2cHf42cScmB5+eWXNWfOHC1btkz5+flatGiRpk2bpt27dystLe2k61NSUvTTn/5UY8aMkcPh0GuvvabZs2crLS1N06ZNkyQ9/vjjevrpp/XCCy9o2LBhevjhhzVt2jTt2LFDLper05rah4ESEhIILAAA9DFdmc5hCfXlh/n5+Zo0aZKeeeYZSW3zR7Kzs3XvvffqoYce6lIbl1xyia677jo9+uijMgxDmZmZmjt3rn70ox9Jkurq6pSenq7nn39et9xyS6ftud1uJSYmqq6ujsACAEAfEcrv75BWCXm9XhUXF6ugoOBEA1arCgoKVFRU1On3DcPQ6tWrtXv3bl1xxRWSpP3796u8vLxDm4mJicrPzz9tmx6PR263u8MHAAD0XyEFlurqavn9fqWnp3c4np6ervLy8tN+r66uTnFxcXI4HLruuuu0ePFiffGLX5Sk4PdCabOwsFCJiYnBDxNuAQDo38KyD0t8fLw2b96sjz/+WD//+c81Z84crV27ttvtzZs3T3V1dcFPaWlpzxULAAAiTkiTblNTU2Wz2VRRUdHheEVFhTIyMk77PavVqhEjRkiScnNztXPnThUWFuqqq64Kfq+iokKDBg3q0GZubu4p23M6nXI6naGUDgAA+rCQelgcDocmTJig1atXB48FAgGtXr1akydP7nI7gUBAHo9HkjRs2DBlZGR0aNPtdmv9+vUhtQkAAPqvkJc1z5kzR7NmzdLEiROVl5enRYsWqbGxUbNnz5YkzZw5U1lZWSosLJTUNt9k4sSJOu+88+TxePTGG2/oN7/5jZYuXSqpbSnT/fffr//4j//QyJEjg8uaMzMzdcMNN/TcnQIAgD4r5MAyffp0VVVVaf78+SovL1dubq5WrVoVnDRbUlLSYXvdxsZG3XXXXTp06JCio6M1ZswY/fa3v9X06dOD1/z4xz9WY2Oj7rjjDtXW1mrq1KlatWpVl/ZgAQAA/V/I+7BEIvZhAQCg7+m1fVgAAADMQGABAAARj8ACAAAiXrfe1nyu8LYGtPDNXfIHAvrJdefLabeZXRIAAOckeljOwJChZz/YrxeKDsrTGjC7HAAAzlkEljOI+ofl2a3+Pr+YCgCAPovAcgZWq0UWS9s/twboYQEAwCwElk6097LQwwIAgHkILJ2w29q6WAgsAACYh8DSCZv1eGBhSAgAANMQWDoRZTs+JBSghwUAALMQWDphP97D4vPTwwIAgFkILJ1oDyx+elgAADANgaUT9uNDQj4m3QIAYBoCSydOrBJiSAgAALMQWDrBkBAAAOYjsHTCfnzjOB+BBQAA0xBYOhHFkBAAAKYjsHTixMZx9LAAAGAWAksn2lcJsTU/AADmIbB0IjgkxNb8AACYhsDSCRtvawYAwHQElk5E8fJDAABMR2DpRPvGcex0CwCAeQgsnWjfh4WN4wAAMA+BpRMnelgYEgIAwCwElk6097CwDwsAAOYhsHSCdwkBAGA+AksnGBICAMB8BJZORLHTLQAApiOwdIJ3CQEAYD4CSyfsvK0ZAADTEVg6EcUqIQAATEdg6YSdlx8CAGA6Aksn2pc1M+kWAADzEFg6YT++Soh3CQEAYB4CSydObBzHkBAAAGYhsHSiPbD4mHQLAIBpCCydsAc3jqOHBQAAsxBYOhFl411CAACYjcDSCZuVSbcAAJiNwNKJKPZhAQDAdASWTtitvPwQAACzEVg6wcsPAQAwH4GlE1G8/BAAANMRWDoRXNZMDwsAAKYhsHSCdwkBAGA+AksnTux0y5AQAABmIbB0on1IiI3jAAAwD4GlEwwJAQBgPgJLJ+zHVwn5WCUEAIBpCCydiGJICAAA0xFYOtG+cRw9LAAAmIfA0okoK/uwAABgNgJLJ6Ls9LAAAGA2AksnHMfnsPj8hgL0sgAAYAoCSycc9hOPyEsvCwAApuhWYFmyZIlycnLkcrmUn5+vDRs2nPba5cuX6/LLL1dycrKSk5NVUFBw0vUNDQ265557NHjwYEVHR2vs2LFatmxZd0rrcf8YWDytBBYAAMwQcmB5+eWXNWfOHC1YsEAbN27U+PHjNW3aNFVWVp7y+rVr12rGjBlas2aNioqKlJ2drWuuuUZlZWXBa+bMmaNVq1bpt7/9rXbu3Kn7779f99xzj1599dXu31kPaR8SkiQvgQUAAFOEHFieeuop3X777Zo9e3awJyQmJkbPPvvsKa9/8cUXdddddyk3N1djxozRr371KwUCAa1evTp4zYcffqhZs2bpqquuUk5Oju644w6NHz/+jD034WKxWIK9LAwJAQBgjpACi9frVXFxsQoKCk40YLWqoKBARUVFXWqjqalJPp9PKSkpwWOXXXaZXn31VZWVlckwDK1Zs0Z79uzRNddcc8o2PB6P3G53h09vch7vZaGHBQAAc4QUWKqrq+X3+5Went7heHp6usrLy7vUxoMPPqjMzMwOoWfx4sUaO3asBg8eLIfDoWuvvVZLlizRFVdccco2CgsLlZiYGPxkZ2eHchshC/awEFgAADBFWFcJLVy4UCtWrNDKlSvlcrmCxxcvXqyPPvpIr776qoqLi/Wf//mfuvvuu/XOO++csp158+aprq4u+CktLe3VugksAACYyx7KxampqbLZbKqoqOhwvKKiQhkZGWf87pNPPqmFCxfqnXfe0bhx44LHm5ub9ZOf/EQrV67UddddJ0kaN26cNm/erCeffLJDT0w7p9Mpp9MZSuln5cQcFn/YfiYAADghpB4Wh8OhCRMmdJgw2z6BdvLkyaf93uOPP65HH31Uq1at0sSJEzuc8/l88vl8slo7lmKz2RQIREaPRvtKIY8vMuoBAOBcE1IPi9S2BHnWrFmaOHGi8vLytGjRIjU2Nmr27NmSpJkzZyorK0uFhYWSpMcee0zz58/XSy+9pJycnOBcl7i4OMXFxSkhIUFXXnmlHnjgAUVHR2vo0KFat26dfv3rX+upp57qwVvtPmfU8cDCKiEAAEwRcmCZPn26qqqqNH/+fJWXlys3N1erVq0KTsQtKSnp0FuydOlSeb1e3XzzzR3aWbBggR555BFJ0ooVKzRv3jzdeuutqqmp0dChQ/Xzn/9cd95551ncWs9xsEoIAABTWQzD6PMvyHG73UpMTFRdXZ0SEhJ6vP1b/rdIH31eo8UzLtZXx2f2ePsAAJyLQvn9zbuEusBht0mihwUAALMQWLogOCTEHBYAAExBYOkCp719lRDLmgEAMAOBpQucvEsIAABTEVi6gJ1uAQAwF4GlCwgsAACYi8DSBcGdbhkSAgDAFASWLqCHBQAAcxFYuqA9sHgILAAAmILA0gVONo4DAMBUBJYuYEgIAABzEVi6gMACAIC5CCxd4GRrfgAATEVg6QJ6WAAAMBeBpQtOrBLiXUIAAJiBwNIFwbc108MCAIApCCxd4IxiHxYAAMxEYOkCB5NuAQAwFYGlC5xRbRvHeXwEFgAAzEBg6QJXFJNuAQAwE4GlC6KP97A0ewksAACYgcDSBa72wOLzyzAMk6sBAODcQ2DpgvbAEjAkn5/AAgBAuBFYuqB9SEhq62UBAADhRWDpgiibRVZL2z+3EFgAAAg7AksXWCyWYC8LgQUAgPAjsHRRtOPExFsAABBeBJYuctpZ2gwAgFkILF3U3sPSwm63AACEHYGli5jDAgCAeQgsXdS+PT9zWAAACD8CSxe56GEBAMA0BJYuio5ilRAAAGYhsHTRiR4WJt0CABBuBJYuYtItAADmIbB0UXDjOPZhAQAg7AgsXeQ8vkqIHhYAAMKPwNJFTLoFAMA8BJYuIrAAAGAeAksXta8S8rBKCACAsCOwdBE9LAAAmIfA0kUuVgkBAGAaAksXtfewNNHDAgBA2BFYuijOaZckNXpaTa4EAIBzD4Gli9oDS0MLgQUAgHAjsHRRnOt4YKGHBQCAsCOwdFFwSMjbqkDAMLkaAADOLQSWLmoPLIbBxFsAAMKNwNJFriirbFaLJOaxAAAQbgSWLrJYLCcm3jKPBQCAsCKwhIDAAgCAOQgsIWBpMwAA5iCwhIClzQAAmIPAEgKGhAAAMAeBJQQnhoR8JlcCAMC5hcASghObx7EPCwAA4URgCUH7HJZ6Jt0CABBWBJYQxAbnsDAkBABAOHUrsCxZskQ5OTlyuVzKz8/Xhg0bTnvt8uXLdfnllys5OVnJyckqKCg45fU7d+7U9ddfr8TERMXGxmrSpEkqKSnpTnm9Jr59SMjDkBAAAOEUcmB5+eWXNWfOHC1YsEAbN27U+PHjNW3aNFVWVp7y+rVr12rGjBlas2aNioqKlJ2drWuuuUZlZWXBa/bt26epU6dqzJgxWrt2rbZs2aKHH35YLper+3fWC+KPDwm5m+lhAQAgnCyGYYT06uH8/HxNmjRJzzzzjCQpEAgoOztb9957rx566KFOv+/3+5WcnKxnnnlGM2fOlCTdcsstioqK0m9+85tu3ILkdruVmJiouro6JSQkdKuNrnhz6xH94MWNmjg0WX/8wWW99nMAADgXhPL7O6QeFq/Xq+LiYhUUFJxowGpVQUGBioqKutRGU1OTfD6fUlJSJLUFntdff12jRo3StGnTlJaWpvz8fP35z38+bRsej0dut7vDJxwSY6IkSbX0sAAAEFYhBZbq6mr5/X6lp6d3OJ6enq7y8vIutfHggw8qMzMzGHoqKyvV0NCghQsX6tprr9Vbb72lG2+8UV//+te1bt26U7ZRWFioxMTE4Cc7OzuU2+i2pGiHJKmOwAIAQFjZw/nDFi5cqBUrVmjt2rXB+SmBQECS9LWvfU3/9m//JknKzc3Vhx9+qGXLlunKK688qZ158+Zpzpw5wT+73e6whJb2Hpa6Jp8Mw5DFYun1nwkAAEIMLKmpqbLZbKqoqOhwvKKiQhkZGWf87pNPPqmFCxfqnXfe0bhx4zq0abfbNXbs2A7Xn3/++Xr//fdP2ZbT6ZTT6Qyl9B6RFN0WWLz+gJp9fsU4wpr3AAA4Z4U0JORwODRhwgStXr06eCwQCGj16tWaPHnyab/3+OOP69FHH9WqVas0ceLEk9qcNGmSdu/e3eH4nj17NHTo0FDK63UxDpuibG29KrVNDAsBABAuIXcRzJkzR7NmzdLEiROVl5enRYsWqbGxUbNnz5YkzZw5U1lZWSosLJQkPfbYY5o/f75eeukl5eTkBOe6xMXFKS4uTpL0wAMPaPr06briiiv0hS98QatWrdJf//pXrV27todus2dYLBYlRkepusGrumafMpOizS4JAIBzQsiBZfr06aqqqtL8+fNVXl6u3NxcrVq1KjgRt6SkRFbriY6bpUuXyuv16uabb+7QzoIFC/TII49Ikm688UYtW7ZMhYWFuu+++zR69Gj96U9/0tSpU8/i1npHe2ChhwUAgPAJeR+WSBSufVgk6aalH6r44DEt+9dLdO2Fg3r1ZwEA0J/12j4saOthkVjaDABAOBFYQtS+UoghIQAAwofAEiJ2uwUAIPwILCFq3+22tslrciUAAJw7CCwhSolrCyxHGwgsAACEC4ElRKmxxwNLI4EFAIBwIbCEKOV4YKkhsAAAEDYElhANiGt7h1F1g8fkSgAAOHcQWEI04HgPS31Lq7ytAZOrAQDg3EBgCVFidJRs1rYXIDIsBABAeBBYQmS1WpQc0z7xlmEhAADCgcDSDaksbQYAIKwILN3ASiEAAMKLwNINrBQCACC8CCzd0D4kVM2QEAAAYUFg6Ya0eJckqdLdYnIlAACcGwgs3ZAW3zYkVFnPkBAAAOFAYOmG9ITjPSz19LAAABAOBJZuSEto62GpcNPDAgBAOBBYuiH9+ByWumafWnx+k6sBAKD/I7B0Q0K0XQ5726OrYh4LAAC9jsDSDRaL5R8m3jKPBQCA3kZg6abgxFvmsQAA0OsILN2UcTywHK6jhwUAgN5GYOmmwSnRkqTSmiaTKwEAoP8jsHTT4OQYSdKhY80mVwIAQP9HYOmm7OS2HpZDx+hhAQCgtxFYuik7pa2HpbSmSYZhmFwNAAD9G4Glm7KS2npYGr1+1Tb5TK4GAID+jcDSTa4oW3AvllKGhQAA6FUElrNwYliIibcAAPQmAstZGMzEWwAAwoLAchayjy9tZkgIAIDeRWA5C9nBzeMYEgIAoDcRWM7Cic3j6GEBAKA3EVjOQvY/7HbLXiwAAPQeAstZGJTkktUieVoDqqrnrc0AAPQWAstZiLJZlXl8A7n91Y0mVwMAQP9FYDlLo9LjJUl7KhtMrgQAgP6LwHKWRme0BZbd5W6TKwEAoP8isJyl0e09LOX0sAAA0FsILGepfUhod0U9K4UAAOglBJazdF5arGxWi+qafapws1IIAIDeQGA5S067TcNSYyW19bIAAICeR2DpASfmsRBYAADoDQSWHtA+j2UXgQUAgF5BYOkB7Uub9zAkBABAryCw9IB/DCyt/oDJ1QAA0P8QWHrA0JQYxTps8rQGtK+KLfoBAOhpBJYeYLVadGFWoiRpy6Fac4sBAKAfIrD0kIuOB5atZXUmVwIAQP9DYOkhFw1u72EhsAAA0NMILD1k3OAkSdKOI275mHgLAECPIrD0kKEpMYp32eVtDbC8GQCAHkZg6SFWq+XEPBaGhQAA6FEElh4UnMfCxFsAAHoUgaUHjctKksTSZgAAelq3AsuSJUuUk5Mjl8ul/Px8bdiw4bTXLl++XJdffrmSk5OVnJysgoKCM15/5513ymKxaNGiRd0pzVTjs9t6WHYdqVeLz29yNQAA9B8hB5aXX35Zc+bM0YIFC7Rx40aNHz9e06ZNU2Vl5SmvX7t2rWbMmKE1a9aoqKhI2dnZuuaaa1RWVnbStStXrtRHH32kzMzM0O8kAmQlRSs1zqnWgKHthxkWAgCgp4QcWJ566indfvvtmj17tsaOHatly5YpJiZGzz777Cmvf/HFF3XXXXcpNzdXY8aM0a9+9SsFAgGtXr26w3VlZWW699579eKLLyoqKqp7d2Myi8Wi3OwkSdKmklpTawEAoD8JKbB4vV4VFxeroKDgRANWqwoKClRUVNSlNpqamuTz+ZSSkhI8FggEdNttt+mBBx7QBRdc0GkbHo9Hbre7wydSXDwkSZK0qbTW1DoAAOhPQgos1dXV8vv9Sk9P73A8PT1d5eXlXWrjwQcfVGZmZofQ89hjj8lut+u+++7rUhuFhYVKTEwMfrKzs7t+E71swtBkSdL6z4/KMAyTqwEAoH8I6yqhhQsXasWKFVq5cqVcLpckqbi4WL/85S/1/PPPy2KxdKmdefPmqa6uLvgpLS3tzbJDcvGQJEVH2VTd4NVuNpADAKBHhBRYUlNTZbPZVFFR0eF4RUWFMjIyzvjdJ598UgsXLtRbb72lcePGBY+/9957qqys1JAhQ2S322W323Xw4EHNnTtXOTk5p2zL6XQqISGhwydSOO02TRrWNtz1wd6jJlcDAED/EFJgcTgcmjBhQocJs+0TaCdPnnza7z3++ON69NFHtWrVKk2cOLHDudtuu01btmzR5s2bg5/MzEw98MAD+tvf/hbi7USGKecNkCR9sLfa5EoAAOgf7KF+Yc6cOZo1a5YmTpyovLw8LVq0SI2NjZo9e7YkaebMmcrKylJhYaGktvkp8+fP10svvaScnJzgXJe4uDjFxcVpwIABGjBgQIefERUVpYyMDI0ePfps788UU0akSmqbx+LzBxRlY38+AADORsiBZfr06aqqqtL8+fNVXl6u3NxcrVq1KjgRt6SkRFbriV/QS5culdfr1c0339yhnQULFuiRRx45u+oj1NhBCUqKiVJtk09bDtVqwtCUzr8EAABOy2L0g6UsbrdbiYmJqquri5j5LHe9WKw3tpZrzhdH6b6rR5pdDgAAESeU39+MVfSSy85rGxZ6n3ksAACcNQJLL2mfx7Kp5JiavK0mVwMAQN9GYOklOQNilJUULZ/f0Ib9NWaXAwBAn0Zg6SUWi0VTj/eyrNtTZXI1AAD0bQSWXvSFMWmSpNU7K9mmHwCAs0Bg6UVTR6bKYbOqpKZJ+6oazC4HAIA+i8DSi+Kcdl16fNfbv356xORqAADouwgsvezGizMlSa9sOqRAgGEhAAC6g8DSy6ZdkKE4p12lNc36+ACrhQAA6A4CSy+Lcdj15Yva3mT9p42HTK4GAIC+icASBjddMliS9MbWcjaRAwCgGwgsYTApJ0XZKdFq8LTqb9vLzS4HAIA+h8ASBlarRV+/uK2X5U/FZSZXAwBA30NgCZP2YaEP9lWrtKbJ5GoAAOhbCCxhMmRAjKaOSJVhSL9df9DscgAA6FMILGE0c/JQSdLvPy5Vi89vcjUAAPQdBJYwuvr8dGUlRetYk0+vbWHnWwAAuorAEkY2q0Xfyh8iSXrug/28EBEAgC4isITZjLwhinHYtP2wW2/tqDC7HAAA+gQCS5ilxDo0e0qOJOm/3t7D+4UAAOgCAosJbr98uOKddu0qr9drW5nLAgBAZwgsJkiKceh7lw+XJP37X7erqt5jckUAAEQ2AotJvn/lcI3JiFd1g1dz//ApQ0MAAJwBgcUkriibFs+4WK4oq/6+p0rL/r7P7JIAAIhYBBYTjUyP1yNfvUCS9OTfdutN5rMAAHBKBBaTTZ+UrRl5QxQwpHt+t0mvs6EcAAAnIbCYzGKx6D9uuFBfvzhL/oCh+1Zs0l8/PWx2WQAARBQCSwSwWS164hvjdfOEwfIHDN3/8mat2kZPCwAA7QgsEcJmtejxm8YFQ8u9v9ukNbsqzS4LAICIQGCJIFarRY/dNE5fGTdIPr+h7/+mmJ4WAABEYIk4NqtF/zU9V9ddNEhef0B3vbhRz32wn31aAADnNAJLBIqyWfX0jIv1zYmDFTCkn/11h+5bsUne1oDZpQEAYAoCS4SyHR8eeuSrYxVls+i1LUf0vV9/okZPq9mlAQAQdgSWCGaxWPTtKcP0q1mTFB1l09/3VOmmpR/q0LEms0sDACCsCCx9wJWjBuql2/OVGufUrvJ63bDkA31aWmt2WQAAhA2BpY+4eEiy/nLPFJ0/KEHVDV7NWP6R1u5m2TMA4NxAYOlDspKi9fvvX6qpI1LV5PXrey98oj8VHzK7LAAAeh2BpY+Jd0Xp2W9P0g25mWoNGJr7h0/132v3yjBY9gwA6L8ILH2Qw27VU9/M1fevGC5JenzVbv3srzvYqwUA0G8RWPooq9WieV8+Xw9/Zawk6fkPD+jeFZvkafWbXBkAAD2PwNLHfXfqMD0942JF2Sx6fcsRzXp2g9wtPrPLAgCgRxFY+oHrx2fq+dl5inPa9dHnNfrmsiJVuFvMLgsAgB5DYOknpoxI1Yo7Lg3u1fL1//5Q5XWEFgBA/0Bg6UcuzErUKz+4TDkDYlRW26wfvFjMnBYAQL9AYOlnhgyI0QvfyVOCy65NJbX62V93mF0SAABnjcDSDw0dEKtfzrhYFov00voSrdhQYnZJAACcFQJLP/WF0WmaUzBKkjT/L9u1qeSYyRUBANB9BJZ+7O4vjNAXx6bL6w/oB7/dqKp6j9klAQDQLQSWfsxqteipb47X8IGxKne36J6XNqrVHzC7LAAAQkZg6efiXVH639smKtZh0/r9Nfr313bw3iEAQJ9DYDkHjEiL0xPfGC9J+nXRQT29eq/JFQEAEBoCyzniyxcN0n/ccKEkadHqPXpre7nJFQEA0HUElnPIv146VDPysmUY0l0vbtQbW4+YXRIAAF1CYDnHPPq1C/W13Ey1Bgzd89JGvfrpYbNLAgCgUwSWc4zdZtVT38zVNyYMVsCQ/u3lzdpyqNbssgAAOCMCyznIZrXosZvG6doLMuQPGJr3ylbeOQQAiGgElnOU1WrRozdcqMToKG0/7NZPV25juTMAIGIRWM5hA+OdWjzjYlkt0h+LD+lX7+03uyQAAE6pW4FlyZIlysnJkcvlUn5+vjZs2HDaa5cvX67LL79cycnJSk5OVkFBQYfrfT6fHnzwQV100UWKjY1VZmamZs6cqcOHmQwaDleMGqiHvzJWkvSLN3fq3V0VJlcEAMDJQg4sL7/8subMmaMFCxZo48aNGj9+vKZNm6bKyspTXr927VrNmDFDa9asUVFRkbKzs3XNNdeorKxMktTU1KSNGzfq4Ycf1saNG/XKK69o9+7duv7668/uztBl374sRzPyhsgwpPt+t1l7KurNLgkAgA4sRogTF/Lz8zVp0iQ988wzkqRAIKDs7Gzde++9euihhzr9vt/vV3Jysp555hnNnDnzlNd8/PHHysvL08GDBzVkyJBO23S73UpMTFRdXZ0SEhJCuR0c520N6Lb/W6/1+2uUnRKtlXdNUWqc0+yyAAD9WCi/v0PqYfF6vSouLlZBQcGJBqxWFRQUqKioqEttNDU1yefzKSUl5bTX1NXVyWKxKCkp6ZTnPR6P3G53hw/OjsNu1bJ/naAhKTEqrWnWdU+/x/AQACBihBRYqqur5ff7lZ6e3uF4enq6ysu7ttX7gw8+qMzMzA6h5x+1tLTowQcf1IwZM06btgoLC5WYmBj8ZGdnh3IbOI3kWIee/fYkDU+NVYXbo+88/4l+9IdP1eJjyTMAwFxhXSW0cOFCrVixQitXrpTL5TrpvM/n0ze/+U0ZhqGlS5eetp158+aprq4u+CktLe3Nss8pI9Li9MYPL9f3pg6T5fjqoR//cYv8AZY8AwDMYw/l4tTUVNlsNlVUdBwqqKioUEZGxhm/++STT2rhwoV65513NG7cuJPOt4eVgwcP6t133z3jWJbT6ZTTyfyK3uKKsun/fWWsLh81UN99/mO9+ulhVbhbtOiWXA1KjDa7PADAOSikHhaHw6EJEyZo9erVwWOBQECrV6/W5MmTT/u9xx9/XI8++qhWrVqliRMnnnS+Pax89tlneueddzRgwIBQykIvuXLUQP3ylosV47Bp/f4afemX7+kvm8vU6g+YXRoA4BwT8pDQnDlztHz5cr3wwgvauXOnfvCDH6ixsVGzZ8+WJM2cOVPz5s0LXv/YY4/p4Ycf1rPPPqucnByVl5ervLxcDQ0NktrCys0336xPPvlEL774ovx+f/Aar9fbQ7eJ7rpu3CC9ft/lujArQbVNPv1wxWbd8N8faF9Vg9mlAQDOISEva5akZ555Rk888YTKy8uVm5urp59+Wvn5+ZKkq666Sjk5OXr++eclSTk5OTp48OBJbSxYsECPPPKIDhw4oGHDhp3y56xZs0ZXXXVVp/WwrLn3eVr9Wrb2cz37wX7VNftkt1p02+ShmvPFUYp3RZldHgCgDwrl93e3AkukIbCEz5G6Zv3kla1as7tKkjQmI17PzZ7E3BYAQMh6bR8WYFBitJ6bnadffydPA+Od2lVerxuXfKh3dlTw8kQAQK8hsKBbrhg1UCvvukwj0+JU7m7R9379ib793Mc62uAxuzQAQD9EYEG3DU6O0cq7p+gHV50nh82qdXuqNPWxNfrpyq1sNgcA6FEEFpyVOKddD147Rq/fN1XnDYxVs8+vF9eXaOb/bVCjp9Xs8gAA/QSBBT1iZHq83vq3K/WrmRMV77Jrw4EaTf/fIh2objS7NABAP0BgQY+xWS0qGJuu33w3X0kxUdpW5tZXFr+vv2wuM7s0AEAfR2BBj8vNTtIb912uSTnJavC06ocrNuv7v/lEG0uOmV0aAKCPIrCgV2QmRet3t1+qe/9lhGxWi/62vUJf/+8PtXTtPpY/AwBCRmBBr7HbrJp7zWi9ft9UXTdukCTpsVW7dNv/bdDnbO0PAAgBgQW9bkxGgpZ86xI9/JWxctqten9vtaYt+rsK39ipuiaf2eUBAPoAtuZHWB082qgFr27X2uNb+ztsVl0xKlU/vnaMRqXHm1wdACCc2JofEWvogFg99+1JevbbEzUmI15ef0Dv7KzUt5Z/pB2H3WaXBwCIUPSwwFR7Kur1by9v1vbDbkXZLLq/YJS+f8Vw2W1kaQDo7+hhQZ8xKj1ev/luvgrOT5fPb+iJv+3WTUs/1JrdlWaXBgCIIPSwICIYhqE/Fh/Sv7+2Q/UtbVv6F5yfrtsmD9WVowaaXB0AoDeE8vubwIKIUulu0dJ1+/TcBweCx2ZPydGsyTnKSY01rzAAQI8jsKDP21xaqxc+PKCVm05s6z91RKq+lT9E116QIavVYmJ1AICeQGBBv/Hurgr9uuig1u2pUvvf1KvHpGn+V8dq6AB6XACgLyOwoN8prWnSyx+X6n/f+1ze1oBsVou+MWGwvjExWxOGJptdHgCgGwgs6Le2HqrTE2/t1t/3VAWPfWH0QH17yjAm5wJAH0NgQb/30edH9fLHpfrL5jIFjv8NHjsoQd+/cri+lptlbnEAgC4hsOCcsbeyQb/96KBeKDoQnONy2XkD9K+XDtUXx6Yrig3oACBiEVhwzjlc26xfFx3U//59X7DHJS3eqVsmZesbE7OVnRJjboEAgJMQWHDOOnSsSb/bUKKXPy5VdYM3eDzWYdOI9Hjdmj9EN10yWDaWRQOA6QgsOOd5WwN6a0e5XvyoROv3Hw32ukjSBZkJ+sq4TN08YbAGxjvNKxIAznEEFuAf1Lf4VOH26J2dFVqyZm9w6/+kmCh98fx03XhJliYOTZHDznwXAAgnAgtwGoeONek3RQf12pYjKqttDh4fGO/Uo1+7QFeNTpMrymZihQBw7iCwAJ1o9vq1bk+V1u6u1JvbylXX7JMkOWxWTZ+UrflfHcsKIwDoZQQWIAQtPr+e+Ntuvb7liMrdLcHj116QoS+MGagvXzRI8a4oEysEgP6JwAJ0g2EYemNruR780xY1eFqDx2McNp0/KEFfy83U5SMHqqbRq8wklwYlRptYLQD0fQQW4Cy0+PzafrhOr2ws07o9VTp0rPmkaxKjo7TsXyfo0uEpsljalkgbhiGf32DyLgB0EYEF6CHe1oB2HnHro8+Pas3uSq3fX6N//C8mKylasU6bAoZ0tMGj1oChR792ob580SCCCwB0gsAC9JKy2mZ5fH4tWbNPb2w9omaf/5TXpcY5NXtKjq69MEPnDYwLc5UA0DcQWIAwaPK2auPBWlksUlW9R9UNHu2ratBb2yt0tPHELrvDUmOVEuvQ4ORoXZydpPQEl744Nl12ViEBOMcRWAATeVsD+vPmMr225YiK9lXL5z/5P7FhqbG6ecJg3XTJYGUkukyoEgDMR2ABIkRds0+fHKiRpzWgHYfd2lpWp00lx+Q+vtuu027V1BGpSktwamC8S9+cOFiDk9te1GgYhgKGeO8RgH6LwAJEsPoWn97cVq4VG0q0saS2wzmn3aq8YSnKH5aiv2w+LJ8/oOdn5yknNdacYgGgFxFYgD7AMAwV7TuqfdWNOtbo1eqdFfr0UN0pr80blqJZk3N0ydAkOe027a9ukMcXUP7wAfTAAOizCCxAH9TqD2hjSa3Wf35U6/ZUyW8YOlDdqGNNvtN+Z0RanGZOHqrc7CRdlJUoi8WiQMBQa4D9YABEPgIL0E8YhqFDx5r1h09K9aeNZapwt6g1YCgjwaUmb2twLowkxTpsGhjvVFltswKGdOPFWbp+fKbSEpwanR6vbWVuxTptGs4yawARgsAC9FOGYcjrD8hpt8nd4tPzHxzQhv01Kj547LR7wkhtc2M8rQFZLdLUkQN1zdh0DUuNVdG+oyp3t2hGXrYmDE3p8HPad/AFgN5CYAHOMZ5Wvw4da9aR2hYNTo7W4dpmvbi+RHsq6lV6rEktvkCnbZw/KEE5A2IUHWXT2j1VGpMRrx9NG63cwUmyWi1q9vpV7/EpLZ5l2AB6BoEFQFCLz69Dx5o0INapynqP1uyu1F8/PSx3i0/jspLkafVr7e4qtQZO/b8Cp92qC7MStaeiXk1ev745MVuXDk/R5OEDJEm7yut1UVaikmMdcrf4dKC6UecPSlAUG+MB6ASBBUBIKt0t2lhyTOV1LSp3e5QQbdfeyga9vuWIPK2d987Eu+y6YtRAbS6pVVlts6JsFl2Ulaj7rh6pK0cNlCQdOtaswcnRDDUBCCKwAOgRrf6A9lY1aHuZW1nJ0SqtaVLR50e1raxOn1U2qKv/93BFWdXiC+jLF2Xo/103Vg67VQHDYHgJOMcRWAD0Om9rQBaLZJH00ec12na4Tr7WgL6VP0T1La16aUOJXvjwwBl7aG67dKi+OTFb56XFKsZhD1/xACICgQVARGj0tKqm0auDR5t0tNGj5e99rl1H6k85XyYz0aW0BJcyjr8c0ma16NoLM+SKskmSapu8WrmpTJcOH6DzB/HfOdAfEFgARKwWn19NXr92HHbr/97/XJtKa1V7ms3xBidH69oLMrTlUJ02lR6Tz28oxmHT/K+M1fW5mfTKAH0cgQVAn1LT6NX+6gZVN3i1cmOZVm0v7/Q7cU67brg4U8NS4xQd1bYvTazTrgszE3T+oIRgzwyAyEVgAdCn1bf4ZLNa9Oz7+7W3skHjBifp6vPTlJ7g0nMfHNCKj0t08GjTGdvITolWSqxTF2cnaXBytCYMTdbh2hY57FaNTo9XUmyUElxRYbojAKdCYAHQrwUChtbsrtTa3VWqcLeoyetXWoJTtU0+fbC3uktLsa0WaUxGgiblJGtgvFNV9R5J0r+cn66JQ5MV62S4CehtBBYA5yxva0D1LT5tO+zWsUavtpbVaV9Vg7YcqlPAMNTk8as1ENBp9smTJMU77br2wgxdNDhRSTEO5eWkKD3Bqc8qG7S5pFZDB8RoWGqs0hJYlg2cDQILAJxGIGAoYBg62ujVhv012nKobdJvarxT1fUefbC3WofrWrrU1gWZCUpwRWlEWpwKxqYrzmmTz2+o2etX/vAUuew2VdS3KMpmVWqcs5fvDOh7CCwA0E3tw02bS2u1ubRWFe4W7aloCJ4flhorf8BQSc2Z59BIksUiGYZkt1p0QVaixg9OVM6AWKXEOpQUE6VBidEamRYnq9WiI3XNio6yKSnG0Zu3B0QUAgsA9KDK+hYFjk+LyUhsGwaqcLdoU0mt6lt82rC/Rh/srZbN1vbagSaPX0cbvV1qOzkmSnEuu0prmmWxSLEOuy4ekqSB8U5lJLhkt1kVHWVTnMuuq0YN1IA4hxw2q/ZVNcpmlT6vatTOI/W69dIh9OKgzyGwAICJAgFDdc0+HW30KNZpV6PHr51H3NpYckxV9R4da/KqptGng0cb1eT198jPTHDZddl5qcpIdMkVZVOsw6bWgKHkmChVNXjkD0hTR6Qqf3hKhxdTBgKGrFbe7wRzEFgAoA/w+QPacqhWzd6ALspKlN8wdOhYk97fWy3DaHsppS/QNiemrLZZxQePyX98trAryiqHzSqf31BLq7/L73WKslk0PDVOidFROljTqMp6j7KSouWKsum8gbGy26wakhIjl92m89JiNSItTqPS4k8KNd7WgAKGoSibVf6AIYedt3MjdL0eWJYsWaInnnhC5eXlGj9+vBYvXqy8vLxTXrt8+XL9+te/1rZt2yRJEyZM0C9+8YsO1xuGoQULFmj58uWqra3VlClTtHTpUo0cObJL9RBYAJwLGj2tag0YqmvyKT3RKae9bXM8nz+gFRtK9Fllg+pbWmUYhlp8AbUGAjpwtEkXZibIbrNqza7KLg9V/bP8YSkakhKjmkavPK0BfXKwRt7WgOxWq7z+gJx2q744Nl1fvyRLrX5DaQku1TR61Oo3NDI9XkNSYmQ7Q0+OYRi8yfsc1KuB5eWXX9bMmTO1bNky5efna9GiRfrDH/6g3bt3Ky0t7aTrb731Vk2ZMkWXXXaZXC6XHnvsMa1cuVLbt29XVlaWJOmxxx5TYWGhXnjhBQ0bNkwPP/ywtm7dqh07dsjl6nzZIIEFADrnDxgqO9ast3aUK2AYmpSTotQ4pw4cbVRDS6v2VjaoyedXpdujlla/jtQ2a1uZW15/5/vadMYVZdW4wUkqOD9NmUnRSot3qbbJq51H6rXi4xLVNvl0UVaislNidMnQJF0yJFnDUmNV4W7R4OS2sGMYhpp9frnsNoax+oleDSz5+fmaNGmSnnnmGUlSIBBQdna27r33Xj300EOdft/v9ys5OVnPPPOMZs6cKcMwlJmZqblz5+pHP/qRJKmurk7p6el6/vnndcstt3TaJoEFAHpHs9evzyrr9ermw4pz2WW1WHS0waPrc7OUGB0lT6tfWUnR2lPRoOc+2K8DR5tktUhV9R4NjG+bBLy3sqFLm/mdjsNuldNuVaOnVQFDSo1zKH/4AA1JidFNl2RpRFp88NpPS2v11o5y/fXTIzpvYKweu3mc4px23jsVoUL5/R3Sv0Gv16vi4mLNmzcveMxqtaqgoEBFRUVdaqOpqUk+n08pKSmSpP3796u8vFwFBQXBaxITE5Wfn6+ioqJTBhaPxyOPxxP8s9vtDuU2AABdFO2wadzgJI0bnHTG6/KGpShvWMopz/kDhvZXN2rt7kr9aWOZ/IGAyo41Ky3BJatF+u7U4RozKF5lx5q1u7xeG0uO6dPSWjUen5DsbQ3I+w+Bp7rBq9e3HJEkPfv+fg1LjZXTbpXNatHGktrgdSU1Tcr7+WpJUlZStIakxGjC0GT5DUM1DV5tP1KnoQNi9dC1Y2S1WnSopkmJMVEanR5/0vCUP2CoptGrd3dV6Orz01mRZYKQAkt1dbX8fr/S09M7HE9PT9euXbu61MaDDz6ozMzMYEApLy8PtvHPbbaf+2eFhYX62c9+FkrpAACT2KwWjUiL04i0OH3v8uGnve6SIcn66vi2f/YHDFW4WzQw3qmSmia9ufWIyt0t+v4V52l/daP2VNTr3V2V+nDfUe0qrw+2YbFIX7owQ2nxLr2+9UjwlQtltc0qq21W0edHO/zMbWXuYPhplxrnVEpslFxRNhmGVN3gUbm7JTix+byBn2vhTePU0NKq3RX1slksuvbCDGWnxKjS3aK3d1boqtFpykhwnXHeDkIT1j6yhQsXasWKFVq7dm2X5qaczrx58zRnzpzgn91ut7Kzs3uiRABABLBZLcpMipYknTcwTvf8y4lFGNkpMbpi1EB9Z8owbSmrU0NLqxq9rWpoadUlQ9vmvkjSgq+OlT9gqNHj165yt4pLjmnroTqlJ7gU77JrZHq8Vmwo0Yf7jspmtSg7OVpH6lpU3eBRdYPnlHVJ0r6qRn1jWcdRhV+8uVOpcSfeSSW1va8qMylaqXFOTcpJ1o0XDz7eC3RMKz4u1SVDknTxkGQda/SqptGr268Yrrjj77Bq9Qf098+qdEFmotJ5BYSkEANLamqqbDabKioqOhyvqKhQRkbGGb/75JNPauHChXrnnXc0bty44PH271VUVGjQoEEd2szNzT1lW06nU04n3XEAcC6zWi3KzU467XmLxSK7zaLEGKvyhw9Q/vABJ13z1XGDVHzwmLJTYpSe4NKxRq82l9bq/b3VKq9rUcHYNGUmRmv4wDg5bFbVNHm14NXt+uRAjbKTYzQiPU7V9R6t31/TIaxIUsCQDh1r1qFjzdpcWqvl7+3vcP7T0lo998GB4J9XbirTlBEDZLda9dHnR/VZZdsOy/FOuy4bMUAj0uI0MSdFhmFoX2WjUmIdumzEAKXFu9QaCOjtHRU6XNusEWlxSo1zdhjG8wcMbS2r05iMeLmibKE/7AjQrUm3eXl5Wrx4saS2SbdDhgzRPffcc9pJt48//rh+/vOf629/+5suvfTSDufaJ93+6Ec/0ty5cyW19ZikpaUx6RYA0CdsPVSneo9PYzISFO+yq/jgMTV5W7XxYK0GJ0fr7R0Ven9vtexWi4YNjFVGQrQkQw2eVjX7AtpWVhfcYydUWUnRChiGjvzTO7CuvSBDl49K1YBYh15cX6L3PqvWsNRYXT8+U9/KH3JSz822sjr919t7lBLrkMUi3XnleRo+MK67j6RLen1Z86xZs/Q///M/ysvL06JFi/T73/9eu3btUnp6umbOnKmsrCwVFhZKaluyPH/+fL300kuaMmVKsJ24uDjFxcUFr1m4cGGHZc1btmxhWTMAoN9oDySnmtdS2+TVW9srdLiuWc1ev7KSo3X9+ExV1nt0uLZZnxw4pqLPj+qzinqlJ7hksUhlx5qDE5Oltrk3afFO7Sx3d2kjwcxElwYnxygzyaVjTT59fKDmpJ2X23pqEuW0WzU4OVpzrxndoz00vbZKSJKmT5+uqqoqzZ8/X+Xl5crNzdWqVauCk2ZLSkpktZ7Y8XDp0qXyer26+eabO7SzYMECPfLII5KkH//4x2psbNQdd9yh2tpaTZ06VatWrTqreS4AAESSM03ATYpx6JuTTp6LmRTj0Kj0eF01+uR9zgIBQ00+v1bvbJum8YUxaUpwRUmS1uyq1N8/q9KaXZWyWi3KHzZA14/P1M4jbr225bA2ltTqcF3LSW8md9isumzEAH1y4JgaPK2qbvDo3V2VkiSn3aqffPn8bt//2WJrfgAAzjFV9R6VHmtSaU2TyutaFOu06/xBCcrNTpLNalEgYOjz6kbtKner7FizomxWNfv8uvsLI3q0jl7tYQEAAH3bwHinBsY7dcmQ5FOet/7DUvRIwduqAABAxCOwAACAiEdgAQAAEY/AAgAAIh6BBQAARDwCCwAAiHgEFgAAEPEILAAAIOIRWAAAQMQjsAAAgIhHYAEAABGPwAIAACIegQUAAES8fvG2ZsMwJLW9phoAAPQN7b+323+Pn0m/CCz19fWSpOzsbJMrAQAAoaqvr1diYuIZr7EYXYk1ES4QCOjw4cOKj4+XxWLp0bbdbreys7NVWlqqhISEHm0bJ/Ccw4dnHR485/DgOYdPbzxrwzBUX1+vzMxMWa1nnqXSL3pYrFarBg8e3Ks/IyEhgf8YwoDnHD486/DgOYcHzzl8evpZd9az0o5JtwAAIOIRWAAAQMQjsHTC6XRqwYIFcjqdZpfSr/Gcw4dnHR485/DgOYeP2c+6X0y6BQAA/Rs9LAAAIOIRWAAAQMQjsAAAgIhHYAEAABGPwAIAACIegaUTS5YsUU5Ojlwul/Lz87VhwwazS+pT/v73v+urX/2qMjMzZbFY9Oc//7nDecMwNH/+fA0aNEjR0dEqKCjQZ5991uGampoa3XrrrUpISFBSUpK++93vqqGhIYx3EfkKCws1adIkxcfHKy0tTTfccIN2797d4ZqWlhbdfffdGjBggOLi4nTTTTepoqKiwzUlJSW67rrrFBMTo7S0ND3wwANqbW0N561EtKVLl2rcuHHBnT4nT56sN998M3ieZ9w7Fi5cKIvFovvvvz94jGfdMx555BFZLJYOnzFjxgTPR9RzNnBaK1asMBwOh/Hss88a27dvN26//XYjKSnJqKioMLu0PuONN94wfvrTnxqvvPKKIclYuXJlh/MLFy40EhMTjT//+c/Gp59+alx//fXGsGHDjObm5uA11157rTF+/Hjjo48+Mt577z1jxIgRxowZM8J8J5Ft2rRpxnPPPWds27bN2Lx5s/HlL3/ZGDJkiNHQ0BC85s477zSys7ON1atXG5988olx6aWXGpdddlnwfGtrq3HhhRcaBQUFxqZNm4w33njDSE1NNebNm2fGLUWkV1991Xj99deNPXv2GLt37zZ+8pOfGFFRUca2bdsMw+AZ94YNGzYYOTk5xrhx44wf/vCHweM8656xYMEC44ILLjCOHDkS/FRVVQXPR9JzJrCcQV5ennH33XcH/+z3+43MzEyjsLDQxKr6rn8OLIFAwMjIyDCeeOKJ4LHa2lrD6XQav/vd7wzDMIwdO3YYkoyPP/44eM2bb75pWCwWo6ysLGy19zWVlZWGJGPdunWGYbQ916ioKOMPf/hD8JqdO3cakoyioiLDMNrCpdVqNcrLy4PXLF261EhISDA8Hk94b6APSU5ONn71q1/xjHtBfX29MXLkSOPtt982rrzyymBg4Vn3nAULFhjjx48/5blIe84MCZ2G1+tVcXGxCgoKgsesVqsKCgpUVFRkYmX9x/79+1VeXt7hGScmJio/Pz/4jIuKipSUlKSJEycGrykoKJDVatX69evDXnNfUVdXJ0lKSUmRJBUXF8vn83V41mPGjNGQIUM6POuLLrpI6enpwWumTZsmt9ut7du3h7H6vsHv92vFihVqbGzU5MmTeca94O6779Z1113X4ZlK/H3uaZ999pkyMzM1fPhw3XrrrSopKZEUec+5X7ytuTdUV1fL7/d3+JcgSenp6dq1a5dJVfUv5eXlknTKZ9x+rry8XGlpaR3O2+12paSkBK9BR4FAQPfff7+mTJmiCy+8UFLbc3Q4HEpKSupw7T8/61P9u2g/hzZbt27V5MmT1dLSori4OK1cuVJjx47V5s2becY9aMWKFdq4caM+/vjjk87x97nn5Ofn6/nnn9fo0aN15MgR/exnP9Pll1+ubdu2RdxzJrAA/czdd9+tbdu26f333ze7lH5p9OjR2rx5s+rq6vTHP/5Rs2bN0rp168wuq18pLS3VD3/4Q7399ttyuVxml9OvfelLXwr+87hx45Sfn6+hQ4fq97//vaKjo02s7GQMCZ1GamqqbDbbSbOhKyoqlJGRYVJV/Uv7czzTM87IyFBlZWWH862traqpqeHfwyncc889eu2117RmzRoNHjw4eDwjI0Ner1e1tbUdrv/nZ32qfxft59DG4XBoxIgRmjBhggoLCzV+/Hj98pe/5Bn3oOLiYlVWVuqSSy6R3W6X3W7XunXr9PTTT8tutys9PZ1n3UuSkpI0atQo7d27N+L+ThNYTsPhcGjChAlavXp18FggENDq1as1efJkEyvrP4YNG6aMjIwOz9jtdmv9+vXBZzx58mTV1taquLg4eM27776rQCCg/Pz8sNccqQzD0D333KOVK1fq3Xff1bBhwzqcnzBhgqKiojo86927d6ukpKTDs966dWuHgPj2228rISFBY8eODc+N9EGBQEAej4dn3IOuvvpqbd26VZs3bw5+Jk6cqFtvvTX4zzzr3tHQ0KB9+/Zp0KBBkfd3uken8PYzK1asMJxOp/H8888bO3bsMO644w4jKSmpw2xonFl9fb2xadMmY9OmTYYk46mnnjI2bdpkHDx40DCMtmXNSUlJxl/+8hdjy5Ytxte+9rVTLmu++OKLjfXr1xvvv/++MXLkSJY1/5Mf/OAHRmJiorF27doOyxObmpqC19x5553GkCFDjHfffdf45JNPjMmTJxuTJ08Onm9fnnjNNdcYmzdvNlatWmUMHDiQZaD/4KGHHjLWrVtn7N+/39iyZYvx0EMPGRaLxXjrrbcMw+AZ96Z/XCVkGDzrnjJ37lxj7dq1xv79+40PPvjAKCgoMFJTU43KykrDMCLrORNYOrF48WJjyJAhhsPhMPLy8oyPPvrI7JL6lDVr1hiSTvrMmjXLMIy2pc0PP/ywkZ6ebjidTuPqq682du/e3aGNo0ePGjNmzDDi4uKMhIQEY/bs2UZ9fb0JdxO5TvWMJRnPPfdc8Jrm5mbjrrvuMpKTk42YmBjjxhtvNI4cOdKhnQMHDhhf+tKXjOjoaCM1NdWYO3eu4fP5wnw3kes73/mOMXToUMPhcBgDBw40rr766mBYMQyecW/658DCs+4Z06dPNwYNGmQ4HA4jKyvLmD59urF3797g+Uh6zhbDMIye7bMBAADoWcxhAQAAEY/AAgAAIh6BBQAARDwCCwAAiHgEFgAAEPEILAAAIOIRWAAAQMQjsAAAgIhHYAEAABGPwAIAACIegQUAAES8/w8OR/I9USSqHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histroy.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18657065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now see Stochastic is unstable where batch_size algorithms are stable and smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554afc0",
   "metadata": {},
   "source": [
    "<p>Vectorization is a process that converts an algorithm from operating on a single value at a time to operating on a set of values (vector) at one time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d477f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's better then loop but it's not work with big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f528b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_batch = 32 it's best "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
